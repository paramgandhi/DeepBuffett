{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)    \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/   \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritikkumar Goyal\n",
    "ragoyal2@wisc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n",
      "\n",
      "matplotlib 3.1.1\n",
      "torch 1.4.0\n",
      "pandas 0.25.1\n",
      "numpy 1.17.2\n",
      "PIL 6.2.0\n",
      "sklearn 0.21.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p matplotlib,torch,pandas,numpy,PIL,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python's Imaging Library (PIL) can be installed via \n",
    "\n",
    "    conda install pillow \n",
    "\n",
    "**If you have any installation issues, please don't hesitate to ask via Piazza!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3: Graduate Student Descent! Training and Tuning a Multilayer Perceptron (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task in this homework is to take this existing Multilayer Perceptron implementation and change it to achieve a better performance on [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist).**\n",
    "\n",
    "---\n",
    "<font color='darkred'>\n",
    "For the successfull outcome of this homework:\n",
    "    \n",
    "- Your Validation and Test set accuracies should be\n",
    "\n",
    "     - greater than 85% for 10 pts\n",
    "     - greater than 86% for 20 pts\n",
    "     - greater than 87% for 30 pts\n",
    "     - greater than 88% for 40 pts    \n",
    "    \n",
    "\n",
    "- Answer the questions at the bottom of this notebook\n",
    "- Submit this Jupyter Notebook with your modifications as .ipynb and .html file to Canvas (similar to previous homeworks)\n",
    "</font>\n",
    "---\n",
    "\n",
    "**And as promised in class, the student with the highest performance will receive a little gift!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read and execute this notebook first to make sure everything works correctly. Then, feel free to make any changes to the architecture, i.e., you can change\n",
    "\n",
    "- the number of layers\n",
    "- the activation function(s) (logistic sigmoid, tanh, relu, leaky relu, ...)\n",
    "- the learning rate\n",
    "- the number of hidden layers\n",
    "- the number of units in the hidden layer(s)\n",
    "- the number of epochs\n",
    "- the minibatch size\n",
    "\n",
    "However,\n",
    "\n",
    "- don't change the weight initialization\n",
    "- don't change the random seed\n",
    "- don't change the optimization algorithm\n",
    "\n",
    "The cells where you can/should make changes are clearly highlighted. For instance, I added comments as shown below:\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything here!\n",
    "# If there is a GPU available, it will use it,\n",
    "# otherwise, it will use the CPU\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 10 classes similar to the original MNIST dataset. Also, it shares the same overall structure with MNIST, i.e., there are 60k training images and 10k test images, and all images are black & white images of size 28x28. \n",
    "\n",
    "Below is an example of how the images look like:\n",
    "\n",
    "![](figures/fashion-mnist-sprite.png)\n",
    "\n",
    "(Image Source: https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 classes in this dataset are\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you continue, please execute the companion notebook \"Notebook for Preparing the Dataset for HW3\" ([`hw3-dataprep.ipynb`](hw3-dataprep.ipynb)) for downloading and preparing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_importance_weights(label_array):\n",
    "    uniq = torch.unique(label_array)\n",
    "    num_examples = label_array.size(0)\n",
    "\n",
    "    m = torch.zeros(uniq.shape[0])\n",
    "\n",
    "    for i, t in enumerate(torch.arange(torch.min(uniq), torch.max(uniq))):\n",
    "        m_k = torch.max(torch.tensor([label_array[label_array > t].size(0), \n",
    "                                      num_examples - label_array[label_array > t].size(0)]))\n",
    "        m[i] = torch.sqrt(m_k.float())\n",
    "\n",
    "    imp = m/torch.max(m)\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"train_normalized.csv\")[\"Label\"].values\n",
    "labels = torch.tensor(labels, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = task_importance_weights(labels)\n",
    "imp = imp[0:NUM_CLASSES-1]\n",
    "imp = imp.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# class FashionMNISTDataset(Dataset):\n",
    "#     \"\"\"Custom Dataset for loading FashionMNIST images\"\"\"\n",
    "\n",
    "#     def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "#         df = pd.read_csv(csv_path)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.img_names = df['image_name'].values\n",
    "#         self.y = df['class_label'].values\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img = Image.open(os.path.join(self.img_dir,\n",
    "#                                       self.img_names[index]))\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "        \n",
    "#         label = self.y[index]\n",
    "#         return img, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.y.shape[0]\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.y = df['Label'].to_numpy().astype(int)\n",
    "        self.features = df.drop([\"Company\", \"Date\", \"Target\", \"Label\"], axis=1).to_numpy().astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index]\n",
    "        label = self.y[index]\n",
    "        \n",
    "        levels = [1]*label + [0]*(NUM_CLASSES - 1 - label)\n",
    "        levels = torch.tensor(levels, dtype=torch.float32)\n",
    "        \n",
    "        return features, label, levels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "custom_train_transform = transforms.Compose([  \n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# THIS CELL CAN BE MODIFIED BUT THERE SHOULD NOT BE ANY RANDOMNESS\n",
    "####################################################################\n",
    "\n",
    "custom_test_transform = transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StockDataset(csv_path='train_normalized.csv')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "\n",
    "valid_dataset = StockDataset(csv_path='val_normalized.csv')\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "test_dataset = StockDataset(csv_path='test_normalized.csv')\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below just checks if the dataset can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 143\n",
    "classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 64\n",
      "break minibatch for-loop\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 64\n",
      "break minibatch for-loop\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y, l) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        num_features = x.shape[1]\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        l = l.to(DEVICE)\n",
    "        print('break minibatch for-loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error, make sure the `png-files` folder is unzipped and it the same directory as this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains the multi-layer perceptron model. This is the main section where you want to make changes to the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "# num_hidden_3,num_hidden_4,num_hidden_5,\n",
    "    def __init__(self, num_features, num_hidden_1, num_hidden_2, num_hidden_3,num_hidden_4,num_hidden_5,num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        ### ADD ADDITIONAL LAYERS BELOW IF YOU LIKE\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.linear_2 = torch.nn.Linear(num_hidden_1, num_hidden_2)\n",
    "        self.linear_3 = torch.nn.Linear(num_hidden_2, num_hidden_3)\n",
    "#         self.linear_4 = torch.nn.Linear(num_hidden_3, num_hidden_4)\n",
    "#         self.linear_5 = torch.nn.Linear(num_hidden_4, num_hidden_5)\n",
    "\n",
    "#         self.linear_out = torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(num_hidden_3, 1, bias=False)\n",
    "        self.linear_1_bias = torch.nn.Parameter(torch.zeros(num_classes-1).float())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### MAKE SURE YOU CONNECT THE LAYERS PROPERLY IF YOU CHANGED\n",
    "        ### ANYTHNG IN THE __init__ METHOD ABOVE       \n",
    "        out = self.linear_1(x)\n",
    "        out = torch.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        \n",
    "        out = self.linear_2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = F.dropout(out, p=0.3, training=self.training)\n",
    "        \n",
    "        out = self.linear_3(out)\n",
    "        out = torch.relu(out)\n",
    "        out = F.dropout(out, p=0.3, training=self.training)\n",
    "        \n",
    "#         out = self.linear_4(out)\n",
    "#         out = torch.relu(out)\n",
    "        \n",
    "#         out = self.linear_5(out)\n",
    "#         out = torch.relu(out)\n",
    "        \n",
    "        logits = self.fc(out)\n",
    "        logits = logits + self.linear_1_bias\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return logits, probas\n",
    "        \n",
    "\n",
    "    \n",
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "\n",
    "\n",
    "# the random seed makes sure that the random weight initialization\n",
    "# in the model is always the same.\n",
    "# In practice, some weights don't work well, and we may also want\n",
    "# to try different random seeds. In this homework, this is not\n",
    "# necessary.\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "### IF YOU CHANGED THE ARCHITECTURE ABOVE, MAKE SURE YOU \n",
    "### ACCOUNT FOR IT VIA THE PARAMETERS BELOW. I.e., if you\n",
    "### added a second hidden layer, you may want to add a\n",
    "### hidden_2 parameter here. Also you may want to play\n",
    "### with the number of hidden units.\n",
    "model = MLP(num_features=num_features,\n",
    "            num_hidden_1=50,\n",
    "            num_hidden_2=50,\n",
    "            num_hidden_3=50,\n",
    "            num_hidden_4=100,\n",
    "            num_hidden_5=100,\n",
    "            num_classes=classes)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "### For this homework, do not change the optimizer. However, you\n",
    "### likely want to experiment with the learning rate!\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "NUM_EPOCHS = 50 # Please feel free to change\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 000/978 | Cost: 4.9915\n",
      "Epoch: 001/050 | Batch 200/978 | Cost: 4.6754\n",
      "Epoch: 001/050 | Batch 400/978 | Cost: 4.4986\n",
      "Epoch: 001/050 | Batch 600/978 | Cost: 4.5036\n",
      "Epoch: 001/050 | Batch 800/978 | Cost: 3.9465\n",
      "MAE/RMSE: | Train: 2.22/2.58 | Test: 2.26/2.64\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 002/050 | Batch 000/978 | Cost: 4.2197\n",
      "Epoch: 002/050 | Batch 200/978 | Cost: 3.9977\n",
      "Epoch: 002/050 | Batch 400/978 | Cost: 4.0727\n",
      "Epoch: 002/050 | Batch 600/978 | Cost: 4.3006\n",
      "Epoch: 002/050 | Batch 800/978 | Cost: 3.5164\n",
      "MAE/RMSE: | Train: 2.22/2.58 | Test: 2.26/2.63\n",
      "Time elapsed: 0.09 min\n",
      "Epoch: 003/050 | Batch 000/978 | Cost: 4.0826\n",
      "Epoch: 003/050 | Batch 200/978 | Cost: 3.7980\n",
      "Epoch: 003/050 | Batch 400/978 | Cost: 3.9706\n",
      "Epoch: 003/050 | Batch 600/978 | Cost: 4.3046\n",
      "Epoch: 003/050 | Batch 800/978 | Cost: 3.3812\n",
      "MAE/RMSE: | Train: 2.22/2.58 | Test: 2.26/2.63\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 004/050 | Batch 000/978 | Cost: 4.0711\n",
      "Epoch: 004/050 | Batch 200/978 | Cost: 3.7499\n",
      "Epoch: 004/050 | Batch 400/978 | Cost: 3.9358\n",
      "Epoch: 004/050 | Batch 600/978 | Cost: 4.3275\n",
      "Epoch: 004/050 | Batch 800/978 | Cost: 3.3292\n",
      "MAE/RMSE: | Train: 2.21/2.58 | Test: 2.26/2.64\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 005/050 | Batch 000/978 | Cost: 4.0803\n",
      "Epoch: 005/050 | Batch 200/978 | Cost: 3.7640\n",
      "Epoch: 005/050 | Batch 400/978 | Cost: 3.9701\n",
      "Epoch: 005/050 | Batch 600/978 | Cost: 4.3512\n",
      "Epoch: 005/050 | Batch 800/978 | Cost: 3.3246\n",
      "MAE/RMSE: | Train: 2.21/2.58 | Test: 2.26/2.63\n",
      "Time elapsed: 0.24 min\n",
      "Epoch: 006/050 | Batch 000/978 | Cost: 4.0445\n",
      "Epoch: 006/050 | Batch 200/978 | Cost: 3.7497\n",
      "Epoch: 006/050 | Batch 400/978 | Cost: 3.9795\n",
      "Epoch: 006/050 | Batch 600/978 | Cost: 4.3460\n",
      "Epoch: 006/050 | Batch 800/978 | Cost: 3.3153\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.63\n",
      "Time elapsed: 0.29 min\n",
      "Epoch: 007/050 | Batch 000/978 | Cost: 4.0588\n",
      "Epoch: 007/050 | Batch 200/978 | Cost: 3.7407\n",
      "Epoch: 007/050 | Batch 400/978 | Cost: 3.9649\n",
      "Epoch: 007/050 | Batch 600/978 | Cost: 4.3608\n",
      "Epoch: 007/050 | Batch 800/978 | Cost: 3.3301\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.34 min\n",
      "Epoch: 008/050 | Batch 000/978 | Cost: 4.1066\n",
      "Epoch: 008/050 | Batch 200/978 | Cost: 3.7532\n",
      "Epoch: 008/050 | Batch 400/978 | Cost: 3.9799\n",
      "Epoch: 008/050 | Batch 600/978 | Cost: 4.4016\n",
      "Epoch: 008/050 | Batch 800/978 | Cost: 3.3119\n",
      "MAE/RMSE: | Train: 2.21/2.58 | Test: 2.26/2.64\n",
      "Time elapsed: 0.39 min\n",
      "Epoch: 009/050 | Batch 000/978 | Cost: 4.0698\n",
      "Epoch: 009/050 | Batch 200/978 | Cost: 3.7273\n",
      "Epoch: 009/050 | Batch 400/978 | Cost: 3.9533\n",
      "Epoch: 009/050 | Batch 600/978 | Cost: 4.3673\n",
      "Epoch: 009/050 | Batch 800/978 | Cost: 3.3354\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 010/050 | Batch 000/978 | Cost: 4.1068\n",
      "Epoch: 010/050 | Batch 200/978 | Cost: 3.7846\n",
      "Epoch: 010/050 | Batch 400/978 | Cost: 3.9833\n",
      "Epoch: 010/050 | Batch 600/978 | Cost: 4.3560\n",
      "Epoch: 010/050 | Batch 800/978 | Cost: 3.2938\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.49 min\n",
      "Epoch: 011/050 | Batch 000/978 | Cost: 4.0869\n",
      "Epoch: 011/050 | Batch 200/978 | Cost: 3.7115\n",
      "Epoch: 011/050 | Batch 400/978 | Cost: 3.9073\n",
      "Epoch: 011/050 | Batch 600/978 | Cost: 4.3870\n",
      "Epoch: 011/050 | Batch 800/978 | Cost: 3.3111\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.54 min\n",
      "Epoch: 012/050 | Batch 000/978 | Cost: 4.0786\n",
      "Epoch: 012/050 | Batch 200/978 | Cost: 3.7675\n",
      "Epoch: 012/050 | Batch 400/978 | Cost: 3.9872\n",
      "Epoch: 012/050 | Batch 600/978 | Cost: 4.3860\n",
      "Epoch: 012/050 | Batch 800/978 | Cost: 3.2774\n",
      "MAE/RMSE: | Train: 2.21/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.59 min\n",
      "Epoch: 013/050 | Batch 000/978 | Cost: 4.0548\n",
      "Epoch: 013/050 | Batch 200/978 | Cost: 3.7804\n",
      "Epoch: 013/050 | Batch 400/978 | Cost: 3.9787\n",
      "Epoch: 013/050 | Batch 600/978 | Cost: 4.3825\n",
      "Epoch: 013/050 | Batch 800/978 | Cost: 3.3172\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.64 min\n",
      "Epoch: 014/050 | Batch 000/978 | Cost: 4.0956\n",
      "Epoch: 014/050 | Batch 200/978 | Cost: 3.7531\n",
      "Epoch: 014/050 | Batch 400/978 | Cost: 3.9574\n",
      "Epoch: 014/050 | Batch 600/978 | Cost: 4.3778\n",
      "Epoch: 014/050 | Batch 800/978 | Cost: 3.3008\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.69 min\n",
      "Epoch: 015/050 | Batch 000/978 | Cost: 4.1159\n",
      "Epoch: 015/050 | Batch 200/978 | Cost: 3.7606\n",
      "Epoch: 015/050 | Batch 400/978 | Cost: 3.9967\n",
      "Epoch: 015/050 | Batch 600/978 | Cost: 4.3131\n",
      "Epoch: 015/050 | Batch 800/978 | Cost: 3.2911\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.25/2.63\n",
      "Time elapsed: 0.74 min\n",
      "Epoch: 016/050 | Batch 000/978 | Cost: 4.1329\n",
      "Epoch: 016/050 | Batch 200/978 | Cost: 3.7273\n",
      "Epoch: 016/050 | Batch 400/978 | Cost: 3.9484\n",
      "Epoch: 016/050 | Batch 600/978 | Cost: 4.3462\n",
      "Epoch: 016/050 | Batch 800/978 | Cost: 3.3412\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.79 min\n",
      "Epoch: 017/050 | Batch 000/978 | Cost: 4.1362\n",
      "Epoch: 017/050 | Batch 200/978 | Cost: 3.7870\n",
      "Epoch: 017/050 | Batch 400/978 | Cost: 3.9851\n",
      "Epoch: 017/050 | Batch 600/978 | Cost: 4.3486\n",
      "Epoch: 017/050 | Batch 800/978 | Cost: 3.2912\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.84 min\n",
      "Epoch: 018/050 | Batch 000/978 | Cost: 4.1433\n",
      "Epoch: 018/050 | Batch 200/978 | Cost: 3.7654\n",
      "Epoch: 018/050 | Batch 400/978 | Cost: 3.9608\n",
      "Epoch: 018/050 | Batch 600/978 | Cost: 4.3891\n",
      "Epoch: 018/050 | Batch 800/978 | Cost: 3.3168\n",
      "MAE/RMSE: | Train: 2.19/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 019/050 | Batch 000/978 | Cost: 4.1230\n",
      "Epoch: 019/050 | Batch 200/978 | Cost: 3.6970\n",
      "Epoch: 019/050 | Batch 400/978 | Cost: 3.9871\n",
      "Epoch: 019/050 | Batch 600/978 | Cost: 4.3379\n",
      "Epoch: 019/050 | Batch 800/978 | Cost: 3.2980\n",
      "MAE/RMSE: | Train: 2.19/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 0.94 min\n",
      "Epoch: 020/050 | Batch 000/978 | Cost: 4.1808\n",
      "Epoch: 020/050 | Batch 200/978 | Cost: 3.7318\n",
      "Epoch: 020/050 | Batch 400/978 | Cost: 3.9614\n",
      "Epoch: 020/050 | Batch 600/978 | Cost: 4.4174\n",
      "Epoch: 020/050 | Batch 800/978 | Cost: 3.3329\n",
      "MAE/RMSE: | Train: 2.20/2.60 | Test: 2.23/2.62\n",
      "Time elapsed: 0.99 min\n",
      "Epoch: 021/050 | Batch 000/978 | Cost: 4.0669\n",
      "Epoch: 021/050 | Batch 200/978 | Cost: 3.7265\n",
      "Epoch: 021/050 | Batch 400/978 | Cost: 3.9635\n",
      "Epoch: 021/050 | Batch 600/978 | Cost: 4.3239\n",
      "Epoch: 021/050 | Batch 800/978 | Cost: 3.2916\n",
      "MAE/RMSE: | Train: 2.19/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 022/050 | Batch 000/978 | Cost: 4.0850\n",
      "Epoch: 022/050 | Batch 200/978 | Cost: 3.7813\n",
      "Epoch: 022/050 | Batch 400/978 | Cost: 3.8778\n",
      "Epoch: 022/050 | Batch 600/978 | Cost: 4.4236\n",
      "Epoch: 022/050 | Batch 800/978 | Cost: 3.3214\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.09 min\n",
      "Epoch: 023/050 | Batch 000/978 | Cost: 4.0832\n",
      "Epoch: 023/050 | Batch 200/978 | Cost: 3.6690\n",
      "Epoch: 023/050 | Batch 400/978 | Cost: 3.9765\n",
      "Epoch: 023/050 | Batch 600/978 | Cost: 4.3402\n",
      "Epoch: 023/050 | Batch 800/978 | Cost: 3.2497\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.14 min\n",
      "Epoch: 024/050 | Batch 000/978 | Cost: 4.1090\n",
      "Epoch: 024/050 | Batch 200/978 | Cost: 3.7126\n",
      "Epoch: 024/050 | Batch 400/978 | Cost: 3.9668\n",
      "Epoch: 024/050 | Batch 600/978 | Cost: 4.3379\n",
      "Epoch: 024/050 | Batch 800/978 | Cost: 3.2357\n",
      "MAE/RMSE: | Train: 2.19/2.57 | Test: 2.26/2.64\n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 025/050 | Batch 000/978 | Cost: 4.1480\n",
      "Epoch: 025/050 | Batch 200/978 | Cost: 3.7032\n",
      "Epoch: 025/050 | Batch 400/978 | Cost: 3.9642\n",
      "Epoch: 025/050 | Batch 600/978 | Cost: 4.3661\n",
      "Epoch: 025/050 | Batch 800/978 | Cost: 3.2907\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.24 min\n",
      "Epoch: 026/050 | Batch 000/978 | Cost: 4.1617\n",
      "Epoch: 026/050 | Batch 200/978 | Cost: 3.7050\n",
      "Epoch: 026/050 | Batch 400/978 | Cost: 3.9548\n",
      "Epoch: 026/050 | Batch 600/978 | Cost: 4.3651\n",
      "Epoch: 026/050 | Batch 800/978 | Cost: 3.2809\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.29 min\n",
      "Epoch: 027/050 | Batch 000/978 | Cost: 4.1364\n",
      "Epoch: 027/050 | Batch 200/978 | Cost: 3.7184\n",
      "Epoch: 027/050 | Batch 400/978 | Cost: 3.9720\n",
      "Epoch: 027/050 | Batch 600/978 | Cost: 4.3646\n",
      "Epoch: 027/050 | Batch 800/978 | Cost: 3.3058\n",
      "MAE/RMSE: | Train: 2.20/2.57 | Test: 2.25/2.63\n",
      "Time elapsed: 1.34 min\n",
      "Epoch: 028/050 | Batch 000/978 | Cost: 4.1139\n",
      "Epoch: 028/050 | Batch 200/978 | Cost: 3.7270\n",
      "Epoch: 028/050 | Batch 400/978 | Cost: 3.9324\n",
      "Epoch: 028/050 | Batch 600/978 | Cost: 4.3399\n",
      "Epoch: 028/050 | Batch 800/978 | Cost: 3.2619\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.24/2.62\n",
      "Time elapsed: 1.39 min\n",
      "Epoch: 029/050 | Batch 000/978 | Cost: 4.1282\n",
      "Epoch: 029/050 | Batch 200/978 | Cost: 3.7261\n",
      "Epoch: 029/050 | Batch 400/978 | Cost: 3.9573\n",
      "Epoch: 029/050 | Batch 600/978 | Cost: 4.3290\n",
      "Epoch: 029/050 | Batch 800/978 | Cost: 3.2861\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.44 min\n",
      "Epoch: 030/050 | Batch 000/978 | Cost: 4.1130\n",
      "Epoch: 030/050 | Batch 200/978 | Cost: 3.6771\n",
      "Epoch: 030/050 | Batch 400/978 | Cost: 3.9493\n",
      "Epoch: 030/050 | Batch 600/978 | Cost: 4.3056\n",
      "Epoch: 030/050 | Batch 800/978 | Cost: 3.2880\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.24/2.62\n",
      "Time elapsed: 1.49 min\n",
      "Epoch: 031/050 | Batch 000/978 | Cost: 4.0648\n",
      "Epoch: 031/050 | Batch 200/978 | Cost: 3.6834\n",
      "Epoch: 031/050 | Batch 400/978 | Cost: 3.8913\n",
      "Epoch: 031/050 | Batch 600/978 | Cost: 4.2843\n",
      "Epoch: 031/050 | Batch 800/978 | Cost: 3.2866\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.53 min\n",
      "Epoch: 032/050 | Batch 000/978 | Cost: 4.0424\n",
      "Epoch: 032/050 | Batch 200/978 | Cost: 3.6691\n",
      "Epoch: 032/050 | Batch 400/978 | Cost: 3.9280\n",
      "Epoch: 032/050 | Batch 600/978 | Cost: 4.2770\n",
      "Epoch: 032/050 | Batch 800/978 | Cost: 3.2891\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.64\n",
      "Time elapsed: 1.59 min\n",
      "Epoch: 033/050 | Batch 000/978 | Cost: 4.1875\n",
      "Epoch: 033/050 | Batch 200/978 | Cost: 3.6929\n",
      "Epoch: 033/050 | Batch 400/978 | Cost: 3.8991\n",
      "Epoch: 033/050 | Batch 600/978 | Cost: 4.2857\n",
      "Epoch: 033/050 | Batch 800/978 | Cost: 3.2953\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.64 min\n",
      "Epoch: 034/050 | Batch 000/978 | Cost: 4.1267\n",
      "Epoch: 034/050 | Batch 200/978 | Cost: 3.6917\n",
      "Epoch: 034/050 | Batch 400/978 | Cost: 3.9415\n",
      "Epoch: 034/050 | Batch 600/978 | Cost: 4.3260\n",
      "Epoch: 034/050 | Batch 800/978 | Cost: 3.2907\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.69 min\n",
      "Epoch: 035/050 | Batch 000/978 | Cost: 4.1851\n",
      "Epoch: 035/050 | Batch 200/978 | Cost: 3.6870\n",
      "Epoch: 035/050 | Batch 400/978 | Cost: 3.9649\n",
      "Epoch: 035/050 | Batch 600/978 | Cost: 4.3366\n",
      "Epoch: 035/050 | Batch 800/978 | Cost: 3.3033\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.74 min\n",
      "Epoch: 036/050 | Batch 000/978 | Cost: 4.0872\n",
      "Epoch: 036/050 | Batch 200/978 | Cost: 3.7277\n",
      "Epoch: 036/050 | Batch 400/978 | Cost: 3.9263\n",
      "Epoch: 036/050 | Batch 600/978 | Cost: 4.4377\n",
      "Epoch: 036/050 | Batch 800/978 | Cost: 3.3265\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.79 min\n",
      "Epoch: 037/050 | Batch 000/978 | Cost: 4.0768\n",
      "Epoch: 037/050 | Batch 200/978 | Cost: 3.6918\n",
      "Epoch: 037/050 | Batch 400/978 | Cost: 3.9857\n",
      "Epoch: 037/050 | Batch 600/978 | Cost: 4.3372\n",
      "Epoch: 037/050 | Batch 800/978 | Cost: 3.2976\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.26/2.64\n",
      "Time elapsed: 1.84 min\n",
      "Epoch: 038/050 | Batch 000/978 | Cost: 4.0976\n",
      "Epoch: 038/050 | Batch 200/978 | Cost: 3.6641\n",
      "Epoch: 038/050 | Batch 400/978 | Cost: 3.9078\n",
      "Epoch: 038/050 | Batch 600/978 | Cost: 4.3468\n",
      "Epoch: 038/050 | Batch 800/978 | Cost: 3.3058\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.89 min\n",
      "Epoch: 039/050 | Batch 000/978 | Cost: 4.2197\n",
      "Epoch: 039/050 | Batch 200/978 | Cost: 3.6879\n",
      "Epoch: 039/050 | Batch 400/978 | Cost: 3.9140\n",
      "Epoch: 039/050 | Batch 600/978 | Cost: 4.3600\n",
      "Epoch: 039/050 | Batch 800/978 | Cost: 3.3394\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.94 min\n",
      "Epoch: 040/050 | Batch 000/978 | Cost: 4.1545\n",
      "Epoch: 040/050 | Batch 200/978 | Cost: 3.6676\n",
      "Epoch: 040/050 | Batch 400/978 | Cost: 3.9689\n",
      "Epoch: 040/050 | Batch 600/978 | Cost: 4.3870\n",
      "Epoch: 040/050 | Batch 800/978 | Cost: 3.3128\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 1.99 min\n",
      "Epoch: 041/050 | Batch 000/978 | Cost: 4.0939\n",
      "Epoch: 041/050 | Batch 200/978 | Cost: 3.6559\n",
      "Epoch: 041/050 | Batch 400/978 | Cost: 3.9886\n",
      "Epoch: 041/050 | Batch 600/978 | Cost: 4.3137\n",
      "Epoch: 041/050 | Batch 800/978 | Cost: 3.2722\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.24/2.62\n",
      "Time elapsed: 2.04 min\n",
      "Epoch: 042/050 | Batch 000/978 | Cost: 4.0633\n",
      "Epoch: 042/050 | Batch 200/978 | Cost: 3.6926\n",
      "Epoch: 042/050 | Batch 400/978 | Cost: 3.8890\n",
      "Epoch: 042/050 | Batch 600/978 | Cost: 4.3716\n",
      "Epoch: 042/050 | Batch 800/978 | Cost: 3.3196\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 2.09 min\n",
      "Epoch: 043/050 | Batch 000/978 | Cost: 4.1815\n",
      "Epoch: 043/050 | Batch 200/978 | Cost: 3.6884\n",
      "Epoch: 043/050 | Batch 400/978 | Cost: 4.0185\n",
      "Epoch: 043/050 | Batch 600/978 | Cost: 4.2854\n",
      "Epoch: 043/050 | Batch 800/978 | Cost: 3.3094\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.64\n",
      "Time elapsed: 2.14 min\n",
      "Epoch: 044/050 | Batch 000/978 | Cost: 4.1627\n",
      "Epoch: 044/050 | Batch 200/978 | Cost: 3.6624\n",
      "Epoch: 044/050 | Batch 400/978 | Cost: 3.8848\n",
      "Epoch: 044/050 | Batch 600/978 | Cost: 4.3100\n",
      "Epoch: 044/050 | Batch 800/978 | Cost: 3.3281\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.24/2.63\n",
      "Time elapsed: 2.19 min\n",
      "Epoch: 045/050 | Batch 000/978 | Cost: 4.1514\n",
      "Epoch: 045/050 | Batch 200/978 | Cost: 3.7256\n",
      "Epoch: 045/050 | Batch 400/978 | Cost: 3.8850\n",
      "Epoch: 045/050 | Batch 600/978 | Cost: 4.3473\n",
      "Epoch: 045/050 | Batch 800/978 | Cost: 3.2644\n",
      "MAE/RMSE: | Train: 2.19/2.56 | Test: 2.26/2.64\n",
      "Time elapsed: 2.24 min\n",
      "Epoch: 046/050 | Batch 000/978 | Cost: 4.1841\n",
      "Epoch: 046/050 | Batch 200/978 | Cost: 3.6871\n",
      "Epoch: 046/050 | Batch 400/978 | Cost: 3.8975\n",
      "Epoch: 046/050 | Batch 600/978 | Cost: 4.4061\n",
      "Epoch: 046/050 | Batch 800/978 | Cost: 3.2597\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 2.29 min\n",
      "Epoch: 047/050 | Batch 000/978 | Cost: 4.0814\n",
      "Epoch: 047/050 | Batch 200/978 | Cost: 3.6656\n",
      "Epoch: 047/050 | Batch 400/978 | Cost: 3.9597\n",
      "Epoch: 047/050 | Batch 600/978 | Cost: 4.3876\n",
      "Epoch: 047/050 | Batch 800/978 | Cost: 3.3187\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 2.35 min\n",
      "Epoch: 048/050 | Batch 000/978 | Cost: 4.1012\n",
      "Epoch: 048/050 | Batch 200/978 | Cost: 3.6493\n",
      "Epoch: 048/050 | Batch 400/978 | Cost: 3.9207\n",
      "Epoch: 048/050 | Batch 600/978 | Cost: 4.2847\n",
      "Epoch: 048/050 | Batch 800/978 | Cost: 3.3006\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.63\n",
      "Time elapsed: 2.40 min\n",
      "Epoch: 049/050 | Batch 000/978 | Cost: 4.1317\n",
      "Epoch: 049/050 | Batch 200/978 | Cost: 3.7007\n",
      "Epoch: 049/050 | Batch 400/978 | Cost: 3.9645\n",
      "Epoch: 049/050 | Batch 600/978 | Cost: 4.2849\n",
      "Epoch: 049/050 | Batch 800/978 | Cost: 3.2905\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.64\n",
      "Time elapsed: 2.44 min\n",
      "Epoch: 050/050 | Batch 000/978 | Cost: 4.0997\n",
      "Epoch: 050/050 | Batch 200/978 | Cost: 3.6945\n",
      "Epoch: 050/050 | Batch 400/978 | Cost: 3.8741\n",
      "Epoch: 050/050 | Batch 600/978 | Cost: 4.3755\n",
      "Epoch: 050/050 | Batch 800/978 | Cost: 3.2968\n",
      "MAE/RMSE: | Train: 2.18/2.56 | Test: 2.25/2.64\n",
      "Time elapsed: 2.49 min\n",
      "Total Training Time: 2.49 min\n"
     ]
    }
   ],
   "source": [
    "def cost_fn(logits, levels, imp):\n",
    "    val = (-torch.sum((F.logsigmoid(logits)*levels\n",
    "                      + (F.logsigmoid(logits) - logits)*(1-levels))*imp,\n",
    "           dim=1))\n",
    "    return torch.mean(val)\n",
    "\n",
    "def compute_mae_and_mse(model, data_loader, device):\n",
    "    mae, mse, num_examples = 0, 0, 0\n",
    "    for i, (features, targets, levels) in enumerate(data_loader):\n",
    "\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        predict_levels = probas > 0.5\n",
    "        predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "        num_examples += targets.size(0)\n",
    "        mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "        mse += torch.sum((predicted_labels - targets)**2)\n",
    "    mae = mae.float() / num_examples\n",
    "    mse = mse.float() / num_examples\n",
    "    return mae, mse\n",
    "\n",
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets, labels) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.view(-1, num_features).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features.float())\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, valid_acc_lst = [], []\n",
    "train_loss_lst, valid_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets, levels) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.view(-1, num_features).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        levels = levels.to(DEVICE)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = cost_fn(logits, levels, imp)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 200:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "#     with torch.set_grad_enabled(False):\n",
    "#         train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "#         valid_acc, valid_loss = compute_accuracy_and_loss(model, valid_loader, device=DEVICE)\n",
    "#         train_acc_lst.append(train_acc)\n",
    "#         valid_acc_lst.append(valid_acc)\n",
    "#         train_loss_lst.append(train_loss)\n",
    "#         valid_loss_lst.append(valid_loss)\n",
    "#         print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "#               f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "    with torch.set_grad_enabled(False):  # save memory during inference\n",
    "        train_mae, train_mse = compute_mae_and_mse(model, train_loader,\n",
    "                                                   device=DEVICE)\n",
    "        test_mae, test_mse = compute_mae_and_mse(model, test_loader,\n",
    "                                                 device=DEVICE)\n",
    "\n",
    "        s = 'MAE/RMSE: | Train: %.2f/%.2f | Test: %.2f/%.2f' % (\n",
    "            train_mae, torch.sqrt(train_mse), test_mae, torch.sqrt(test_mse))\n",
    "        print(s)\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation (No Need To Change Any Code in This Section!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-88a4a30a6c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (0,)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11e969b90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ritik/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/ritik/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/Users/ritik/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/ritik/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Users/ritik/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEUElEQVR4nO3aMapbBxBA0TfBndtoDXEfrUmL+mvS77ILeQOpJk1AYBIUg60bW+d0ejzEMMUthje7ewDwfL/UAwC8KgEGiAgwQESAASICDBARYIDIh0cvzMzlOI7LcRzHx48ff//06dN3HwrgZ/L+/v55d09fPp+v+Q74fD7v9Xr9poMB/Oxm5n13z18+d4IAiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiDwM8MxcZuY6M9fb7faMmQBewsMA7+7b7p5393w6nZ4xE8BLcIIAiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQORhgGfmMjPXmbnebrdnzATwEh4GeHffdve8u+fT6fSMmQBeghMEQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQORhgGfmMjPXmbnebrdnzATwEh4GeHffdve8u+fT6fSMmQBeghMEQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASIPAzwzl5m5zsz1drs9YyaAl/AwwLv7trvn3T2fTqdnzATwEpwgACICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASIfHr0wM5fjOC5///xzZv74viP9MH49juNzPcT/hF3c2cWdXdz99k8PZ3f/8z/MzHV3z99spB+YXdzZxZ1d3NnF3b/twgkCICLAAJGvDfDbd5nix2QXd3ZxZxd3dnH3j7v4qhswAN+OEwRARIABIgIMEBFggIgAA0T+AnrnfC3cGvwQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_loss_lst, label='Training loss')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), valid_loss_lst, label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d12949236de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_acc_lst, label='Training accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), valid_acc_lst, label='Validation accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 8 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-400cb4f49555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# save memory during inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {test_acc:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-47cc0df04d3a>\u001b[0m in \u001b[0;36mcompute_accuracy_and_loss\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcross_entropy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mnum_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 8 is out of bounds."
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, DEVICE)\n",
    "    print(f'Test accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7135\n",
      "17071\n"
     ]
    }
   ],
   "source": [
    "all_pred = []\n",
    "all_probas = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, (features, targets, levels) in enumerate(test_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        logits, probas = model(features)\n",
    "        all_probas.append(probas)\n",
    "        predict_levels = probas > 0.5\n",
    "        predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "        lst = [str(int(i)) for i in predicted_labels]\n",
    "#         print(predicted_labels)\n",
    "#         print(targets)\n",
    "#         break\n",
    "        for i in range(len(lst)):\n",
    "            total += 1\n",
    "            c = 0\n",
    "            if targets[i].item() in [0, 1, 2, 3] and predicted_labels[i] <= 3:\n",
    "                c = 1\n",
    "            elif targets[i].item() == 4 and predicted_labels[i] == 4:\n",
    "                c = 1  \n",
    "            elif targets[i].item() in [5, 6, 7, 8] and predicted_labels[i] >= 5 and predicted_labels[i] <= 8:\n",
    "                c = 1 \n",
    "            if abs(targets[i].item() - predicted_labels[i]) <= 1:\n",
    "                c = 1\n",
    "            correct += c\n",
    "        all_pred.extend(lst)\n",
    "print(correct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 5, 4, 5, 4, 5,\n",
      "        3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3])\n",
      "tensor([6, 6, 4, 4, 4, 6, 1, 0, 5, 8, 1, 1, 8, 6, 0, 8, 2, 1, 2, 3, 1, 7, 4, 1,\n",
      "        5, 1, 2, 7, 2, 4, 2, 1, 1, 2, 6, 6, 2, 5, 1, 5, 7, 7, 6, 2, 1, 6, 3, 7,\n",
      "        4, 4, 4, 7, 2, 4, 0, 3, 0, 4, 8, 5, 3, 7, 1, 6])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    for i, (x, y, l) in enumerate(test_loader):\n",
    "        if i == num:\n",
    "            logits, probas = model(x)\n",
    "            predict_levels = probas > 0.5\n",
    "            predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "            print(predicted_labels)\n",
    "#             print(np.argmax(probas, axis=1))\n",
    "            print(y)\n",
    "            print(y[4].item() == np.argmax(probas, axis=1)[4].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions (YOUR ANSWERS REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) What is your training, validation, and test accuracy (paste your numbers from above)? Also, do you notice any overfitting? If yes, why do you think your model is overfitting, and what would be a simple technique to reduce overfitting?**\n",
    "\n",
    "- Training:  94.52%\n",
    "- Validation: 89.68%\n",
    "- Test 89.24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes: \n",
    "- Added 3 hidden layers with 1000 units each and Relu activations\n",
    "- Changed output activation function to Softmax\n",
    "- Increased the learning rate to 0.1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the model is overfitting because the training accuracy keeps improving while the validation accuracy stays the same or decreases after a certain point. This implies that the model is learning too much about the training data and hence, overfitting. A simple way to reduce overfitting would be to use L1/L2 regularization, add dropout layers or reduce the complexity/capacity of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Assuming you increased the accuracy by 3%, how many more correct predictions did the improved model make in the test set?**\n",
    "\n",
    "The test dataset has 10,000 images. So, a 3% increase in accuracy means that the model made 300 more correct predictions.\n",
    "\n",
    "10000 * 0.03 = 300 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
