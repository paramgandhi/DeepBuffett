{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyMetrics(stock):\n",
    "    url = \"https://financialmodelingprep.com/api/v3/company-key-metrics/\" + stock + \"?period=quarter\"\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(response.text)\n",
    "        return data[\"metrics\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinancialGrowth(stock):\n",
    "    url = \"https://financialmodelingprep.com/api/v3/financial-statement-growth/\" + stock + \"?period=quarter\"\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(response.text)\n",
    "        return data[\"growth\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiscountedCashFlow(stock):\n",
    "    url = \"https://financialmodelingprep.com/api/v3/company/historical-discounted-cash-flow/\" + stock + \"?period=quarter\"\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(response.text)\n",
    "        return data[\"historicalDCF\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(stock):\n",
    "    df1 = pd.read_csv(\"api_data/income_statements/\" + stock + \".csv\")\n",
    "    df2 = pd.read_csv(\"api_data/balance_sheets/\" + stock + \".csv\")\n",
    "    df3 = pd.read_csv(\"api_data/cash_flow_statements/\" + stock + \".csv\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.concat([df1,df2,df3], axis=0, ignore_index=True, sort=False).T.reset_index()\n",
    "    except:\n",
    "        print(\"Error: \"+ stock)\n",
    "        return\n",
    "    new_header = df.iloc[0] \n",
    "    df = df[1:] \n",
    "    df.columns = new_header\n",
    "\n",
    "    cols = list(df.columns.values)\n",
    "    df[\"Company\"] = stock\n",
    "\n",
    "    cols.insert(0, \"Company\")\n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    keyMetrics = getKeyMetrics(stock)\n",
    "    financialGrowth = getFinancialGrowth(stock)\n",
    "    dcf = getDiscountedCashFlow(stock)\n",
    "    \n",
    "    if keyMetrics is not None:\n",
    "        keyMetrics = pd.DataFrame(keyMetrics).rename(columns={'date': 'Date'})\n",
    "        df = df.merge(keyMetrics, how=\"outer\", left_on=[\"Date\"], right_on=[\"Date\"])\n",
    "\n",
    "    if financialGrowth is not None:\n",
    "        financialGrowth = pd.DataFrame(financialGrowth).rename(columns={'date': 'Date'})\n",
    "        df = df.merge(financialGrowth, how=\"outer\", left_on=[\"Date\"], right_on=[\"Date\"])\n",
    "\n",
    "    if dcf is not None:\n",
    "        dcf = pd.DataFrame(dcf).rename(columns={'date': 'Date'})\n",
    "        df = df.merge(dcf, how=\"outer\", left_on=[\"Date\"], right_on=[\"Date\"])\n",
    "\n",
    "    output_file = \"api_data/processed/\" + stock + \".csv\"\n",
    "    df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(stock_chunks):\n",
    "    for stock in stock_chunks:\n",
    "        process(stock)\n",
    "    print(\"Done chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = set(os.listdir(\"api_data/income_statements\"))\n",
    "files2 = set(os.listdir(\"api_data/balance_sheets\"))\n",
    "files3 = set(os.listdir(\"api_data/cash_flow_statements\"))\n",
    "\n",
    "files = list(files1.intersection(files2).intersection(files3))\n",
    "\n",
    "stocks = list(map(lambda x: x[:-4], files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(alist, wanted_parts=1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_chunked = split_list(stocks, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n",
      "Done chunk\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(processes=32)\n",
    "results = [pool.apply_async(process_chunk, args=(stock_chunk,)) for stock_chunk in stocks_chunked]\n",
    "output = [p.get() for p in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
