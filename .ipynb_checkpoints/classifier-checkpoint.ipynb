{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)    \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/   \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritikkumar Goyal\n",
    "ragoyal2@wisc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n",
      "\n",
      "matplotlib 3.1.1\n",
      "torch 1.4.0\n",
      "pandas 0.25.1\n",
      "numpy 1.17.2\n",
      "PIL 6.2.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p matplotlib,torch,pandas,numpy,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python's Imaging Library (PIL) can be installed via \n",
    "\n",
    "    conda install pillow \n",
    "\n",
    "**If you have any installation issues, please don't hesitate to ask via Piazza!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3: Graduate Student Descent! Training and Tuning a Multilayer Perceptron (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task in this homework is to take this existing Multilayer Perceptron implementation and change it to achieve a better performance on [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist).**\n",
    "\n",
    "---\n",
    "<font color='darkred'>\n",
    "For the successfull outcome of this homework:\n",
    "    \n",
    "- Your Validation and Test set accuracies should be\n",
    "\n",
    "     - greater than 85% for 10 pts\n",
    "     - greater than 86% for 20 pts\n",
    "     - greater than 87% for 30 pts\n",
    "     - greater than 88% for 40 pts    \n",
    "    \n",
    "\n",
    "- Answer the questions at the bottom of this notebook\n",
    "- Submit this Jupyter Notebook with your modifications as .ipynb and .html file to Canvas (similar to previous homeworks)\n",
    "</font>\n",
    "---\n",
    "\n",
    "**And as promised in class, the student with the highest performance will receive a little gift!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read and execute this notebook first to make sure everything works correctly. Then, feel free to make any changes to the architecture, i.e., you can change\n",
    "\n",
    "- the number of layers\n",
    "- the activation function(s) (logistic sigmoid, tanh, relu, leaky relu, ...)\n",
    "- the learning rate\n",
    "- the number of hidden layers\n",
    "- the number of units in the hidden layer(s)\n",
    "- the number of epochs\n",
    "- the minibatch size\n",
    "\n",
    "However,\n",
    "\n",
    "- don't change the weight initialization\n",
    "- don't change the random seed\n",
    "- don't change the optimization algorithm\n",
    "\n",
    "The cells where you can/should make changes are clearly highlighted. For instance, I added comments as shown below:\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything here!\n",
    "# If there is a GPU available, it will use it,\n",
    "# otherwise, it will use the CPU\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 10 classes similar to the original MNIST dataset. Also, it shares the same overall structure with MNIST, i.e., there are 60k training images and 10k test images, and all images are black & white images of size 28x28. \n",
    "\n",
    "Below is an example of how the images look like:\n",
    "\n",
    "![](figures/fashion-mnist-sprite.png)\n",
    "\n",
    "(Image Source: https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 classes in this dataset are\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you continue, please execute the companion notebook \"Notebook for Preparing the Dataset for HW3\" ([`hw3-dataprep.ipynb`](hw3-dataprep.ipynb)) for downloading and preparing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# class FashionMNISTDataset(Dataset):\n",
    "#     \"\"\"Custom Dataset for loading FashionMNIST images\"\"\"\n",
    "\n",
    "#     def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "#         df = pd.read_csv(csv_path)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.img_names = df['image_name'].values\n",
    "#         self.y = df['class_label'].values\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img = Image.open(os.path.join(self.img_dir,\n",
    "#                                       self.img_names[index]))\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "        \n",
    "#         label = self.y[index]\n",
    "#         return img, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.y.shape[0]\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.y = df['Label'].to_numpy().astype(int)\n",
    "        self.features = df.drop([\"Company\", \"Date\", \"Target\", \"Label\"], axis=1).to_numpy().astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index]\n",
    "        label = self.y[index]\n",
    "        \n",
    "        return features, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "custom_train_transform = transforms.Compose([  \n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# THIS CELL CAN BE MODIFIED BUT THERE SHOULD NOT BE ANY RANDOMNESS\n",
    "####################################################################\n",
    "\n",
    "custom_test_transform = transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StockDataset(csv_path='train.csv')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "\n",
    "valid_dataset = StockDataset(csv_path='val.csv')\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "test_dataset = StockDataset(csv_path='test.csv')\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below just checks if the dataset can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 64\n",
      "break minibatch for-loop\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 64\n",
      "break minibatch for-loop\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        print('break minibatch for-loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error, make sure the `png-files` folder is unzipped and it the same directory as this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains the multi-layer perceptron model. This is the main section where you want to make changes to the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "# num_hidden_3,num_hidden_4,num_hidden_5,\n",
    "    def __init__(self, num_features, num_hidden_1, num_hidden_2,  num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        ### ADD ADDITIONAL LAYERS BELOW IF YOU LIKE\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.linear_2 = torch.nn.Linear(num_hidden_1, num_hidden_2)\n",
    "#         self.linear_3 = torch.nn.Linear(num_hidden_2, num_hidden_3)\n",
    "#         self.linear_4 = torch.nn.Linear(num_hidden_3, num_hidden_4)\n",
    "#         self.linear_5 = torch.nn.Linear(num_hidden_4, num_hidden_5)\n",
    "\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### MAKE SURE YOU CONNECT THE LAYERS PROPERLY IF YOU CHANGED\n",
    "        ### ANYTHNG IN THE __init__ METHOD ABOVE       \n",
    "        out = self.linear_1(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        out = self.linear_2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "#         out = self.linear_3(out)\n",
    "#         out = torch.sigmoid(out)\n",
    "        \n",
    "#         out = self.linear_4(out)\n",
    "#         out = torch.sigmoid(out)\n",
    "        \n",
    "#         out = self.linear_5(out)\n",
    "#         out = torch.sigmoid(out)\n",
    "        \n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "        \n",
    "\n",
    "    \n",
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "\n",
    "\n",
    "# the random seed makes sure that the random weight initialization\n",
    "# in the model is always the same.\n",
    "# In practice, some weights don't work well, and we may also want\n",
    "# to try different random seeds. In this homework, this is not\n",
    "# necessary.\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "### IF YOU CHANGED THE ARCHITECTURE ABOVE, MAKE SURE YOU \n",
    "### ACCOUNT FOR IT VIA THE PARAMETERS BELOW. I.e., if you\n",
    "### added a second hidden layer, you may want to add a\n",
    "### hidden_2 parameter here. Also you may want to play\n",
    "### with the number of hidden units.\n",
    "model = MLP(num_features=143,\n",
    "            num_hidden_1=256,\n",
    "            num_hidden_2=256,\n",
    "#             num_hidden_3=256,\n",
    "#             num_hidden_4=256,\n",
    "#             num_hidden_5=256,\n",
    "            num_classes=3)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "### For this homework, do not change the optimizer. However, you\n",
    "### likely want to experiment with the learning rate!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# THIS CELL CAN BE MODIFIED\n",
    "############################################################\n",
    "\n",
    "NUM_EPOCHS = 200 # Please feel free to change\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/200 | Batch 000/981 | Cost: 1.0853\n",
      "Epoch: 001/200 | Batch 200/981 | Cost: 1.0101\n",
      "Epoch: 001/200 | Batch 400/981 | Cost: 1.1080\n",
      "Epoch: 001/200 | Batch 600/981 | Cost: 1.0357\n",
      "Epoch: 001/200 | Batch 800/981 | Cost: 1.1025\n",
      "Epoch: 001/200 Train Acc.: 28.09% | Validation Acc.: 28.92%\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 002/200 | Batch 000/981 | Cost: 1.3309\n",
      "Epoch: 002/200 | Batch 200/981 | Cost: 0.9883\n",
      "Epoch: 002/200 | Batch 400/981 | Cost: 1.0653\n",
      "Epoch: 002/200 | Batch 600/981 | Cost: 1.0204\n",
      "Epoch: 002/200 | Batch 800/981 | Cost: 1.0872\n",
      "Epoch: 002/200 Train Acc.: 29.68% | Validation Acc.: 30.83%\n",
      "Time elapsed: 0.07 min\n",
      "Epoch: 003/200 | Batch 000/981 | Cost: 1.2220\n",
      "Epoch: 003/200 | Batch 200/981 | Cost: 0.9868\n",
      "Epoch: 003/200 | Batch 400/981 | Cost: 1.0545\n",
      "Epoch: 003/200 | Batch 600/981 | Cost: 1.0185\n",
      "Epoch: 003/200 | Batch 800/981 | Cost: 1.0802\n",
      "Epoch: 003/200 Train Acc.: 30.44% | Validation Acc.: 31.31%\n",
      "Time elapsed: 0.11 min\n",
      "Epoch: 004/200 | Batch 000/981 | Cost: 1.1795\n",
      "Epoch: 004/200 | Batch 200/981 | Cost: 0.9847\n",
      "Epoch: 004/200 | Batch 400/981 | Cost: 1.0510\n",
      "Epoch: 004/200 | Batch 600/981 | Cost: 1.0190\n",
      "Epoch: 004/200 | Batch 800/981 | Cost: 1.0762\n",
      "Epoch: 004/200 Train Acc.: 31.55% | Validation Acc.: 32.62%\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 005/200 | Batch 000/981 | Cost: 1.1576\n",
      "Epoch: 005/200 | Batch 200/981 | Cost: 0.9825\n",
      "Epoch: 005/200 | Batch 400/981 | Cost: 1.0497\n",
      "Epoch: 005/200 | Batch 600/981 | Cost: 1.0199\n",
      "Epoch: 005/200 | Batch 800/981 | Cost: 1.0738\n",
      "Epoch: 005/200 Train Acc.: 32.61% | Validation Acc.: 34.31%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 006/200 | Batch 000/981 | Cost: 1.1447\n",
      "Epoch: 006/200 | Batch 200/981 | Cost: 0.9804\n",
      "Epoch: 006/200 | Batch 400/981 | Cost: 1.0493\n",
      "Epoch: 006/200 | Batch 600/981 | Cost: 1.0208\n",
      "Epoch: 006/200 | Batch 800/981 | Cost: 1.0721\n",
      "Epoch: 006/200 Train Acc.: 33.74% | Validation Acc.: 35.55%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 007/200 | Batch 000/981 | Cost: 1.1362\n",
      "Epoch: 007/200 | Batch 200/981 | Cost: 0.9786\n",
      "Epoch: 007/200 | Batch 400/981 | Cost: 1.0490\n",
      "Epoch: 007/200 | Batch 600/981 | Cost: 1.0215\n",
      "Epoch: 007/200 | Batch 800/981 | Cost: 1.0708\n",
      "Epoch: 007/200 Train Acc.: 34.67% | Validation Acc.: 35.98%\n",
      "Time elapsed: 0.25 min\n",
      "Epoch: 008/200 | Batch 000/981 | Cost: 1.1301\n",
      "Epoch: 008/200 | Batch 200/981 | Cost: 0.9771\n",
      "Epoch: 008/200 | Batch 400/981 | Cost: 1.0487\n",
      "Epoch: 008/200 | Batch 600/981 | Cost: 1.0221\n",
      "Epoch: 008/200 | Batch 800/981 | Cost: 1.0697\n",
      "Epoch: 008/200 Train Acc.: 35.41% | Validation Acc.: 36.77%\n",
      "Time elapsed: 0.29 min\n",
      "Epoch: 009/200 | Batch 000/981 | Cost: 1.1254\n",
      "Epoch: 009/200 | Batch 200/981 | Cost: 0.9759\n",
      "Epoch: 009/200 | Batch 400/981 | Cost: 1.0484\n",
      "Epoch: 009/200 | Batch 600/981 | Cost: 1.0225\n",
      "Epoch: 009/200 | Batch 800/981 | Cost: 1.0687\n",
      "Epoch: 009/200 Train Acc.: 36.12% | Validation Acc.: 37.31%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 010/200 | Batch 000/981 | Cost: 1.1215\n",
      "Epoch: 010/200 | Batch 200/981 | Cost: 0.9749\n",
      "Epoch: 010/200 | Batch 400/981 | Cost: 1.0481\n",
      "Epoch: 010/200 | Batch 600/981 | Cost: 1.0228\n",
      "Epoch: 010/200 | Batch 800/981 | Cost: 1.0677\n",
      "Epoch: 010/200 Train Acc.: 36.68% | Validation Acc.: 37.98%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 011/200 | Batch 000/981 | Cost: 1.1181\n",
      "Epoch: 011/200 | Batch 200/981 | Cost: 0.9740\n",
      "Epoch: 011/200 | Batch 400/981 | Cost: 1.0477\n",
      "Epoch: 011/200 | Batch 600/981 | Cost: 1.0230\n",
      "Epoch: 011/200 | Batch 800/981 | Cost: 1.0668\n",
      "Epoch: 011/200 Train Acc.: 37.16% | Validation Acc.: 38.82%\n",
      "Time elapsed: 0.40 min\n",
      "Epoch: 012/200 | Batch 000/981 | Cost: 1.1151\n",
      "Epoch: 012/200 | Batch 200/981 | Cost: 0.9733\n",
      "Epoch: 012/200 | Batch 400/981 | Cost: 1.0474\n",
      "Epoch: 012/200 | Batch 600/981 | Cost: 1.0232\n",
      "Epoch: 012/200 | Batch 800/981 | Cost: 1.0660\n",
      "Epoch: 012/200 Train Acc.: 37.61% | Validation Acc.: 39.43%\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 013/200 | Batch 000/981 | Cost: 1.1125\n",
      "Epoch: 013/200 | Batch 200/981 | Cost: 0.9728\n",
      "Epoch: 013/200 | Batch 400/981 | Cost: 1.0471\n",
      "Epoch: 013/200 | Batch 600/981 | Cost: 1.0232\n",
      "Epoch: 013/200 | Batch 800/981 | Cost: 1.0651\n",
      "Epoch: 013/200 Train Acc.: 38.02% | Validation Acc.: 39.70%\n",
      "Time elapsed: 0.48 min\n",
      "Epoch: 014/200 | Batch 000/981 | Cost: 1.1101\n",
      "Epoch: 014/200 | Batch 200/981 | Cost: 0.9723\n",
      "Epoch: 014/200 | Batch 400/981 | Cost: 1.0468\n",
      "Epoch: 014/200 | Batch 600/981 | Cost: 1.0232\n",
      "Epoch: 014/200 | Batch 800/981 | Cost: 1.0643\n",
      "Epoch: 014/200 Train Acc.: 38.26% | Validation Acc.: 39.98%\n",
      "Time elapsed: 0.52 min\n",
      "Epoch: 015/200 | Batch 000/981 | Cost: 1.1080\n",
      "Epoch: 015/200 | Batch 200/981 | Cost: 0.9719\n",
      "Epoch: 015/200 | Batch 400/981 | Cost: 1.0466\n",
      "Epoch: 015/200 | Batch 600/981 | Cost: 1.0232\n",
      "Epoch: 015/200 | Batch 800/981 | Cost: 1.0635\n",
      "Epoch: 015/200 Train Acc.: 38.55% | Validation Acc.: 40.43%\n",
      "Time elapsed: 0.55 min\n",
      "Epoch: 016/200 | Batch 000/981 | Cost: 1.1061\n",
      "Epoch: 016/200 | Batch 200/981 | Cost: 0.9715\n",
      "Epoch: 016/200 | Batch 400/981 | Cost: 1.0464\n",
      "Epoch: 016/200 | Batch 600/981 | Cost: 1.0232\n",
      "Epoch: 016/200 | Batch 800/981 | Cost: 1.0627\n",
      "Epoch: 016/200 Train Acc.: 38.88% | Validation Acc.: 40.55%\n",
      "Time elapsed: 0.59 min\n",
      "Epoch: 017/200 | Batch 000/981 | Cost: 1.1044\n",
      "Epoch: 017/200 | Batch 200/981 | Cost: 0.9712\n",
      "Epoch: 017/200 | Batch 400/981 | Cost: 1.0463\n",
      "Epoch: 017/200 | Batch 600/981 | Cost: 1.0231\n",
      "Epoch: 017/200 | Batch 800/981 | Cost: 1.0619\n",
      "Epoch: 017/200 Train Acc.: 39.16% | Validation Acc.: 40.73%\n",
      "Time elapsed: 0.63 min\n",
      "Epoch: 018/200 | Batch 000/981 | Cost: 1.1028\n",
      "Epoch: 018/200 | Batch 200/981 | Cost: 0.9710\n",
      "Epoch: 018/200 | Batch 400/981 | Cost: 1.0461\n",
      "Epoch: 018/200 | Batch 600/981 | Cost: 1.0230\n",
      "Epoch: 018/200 | Batch 800/981 | Cost: 1.0611\n",
      "Epoch: 018/200 Train Acc.: 39.34% | Validation Acc.: 40.91%\n",
      "Time elapsed: 0.66 min\n",
      "Epoch: 019/200 | Batch 000/981 | Cost: 1.1014\n",
      "Epoch: 019/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 019/200 | Batch 400/981 | Cost: 1.0460\n",
      "Epoch: 019/200 | Batch 600/981 | Cost: 1.0228\n",
      "Epoch: 019/200 | Batch 800/981 | Cost: 1.0604\n",
      "Epoch: 019/200 Train Acc.: 39.58% | Validation Acc.: 41.22%\n",
      "Time elapsed: 0.70 min\n",
      "Epoch: 020/200 | Batch 000/981 | Cost: 1.1001\n",
      "Epoch: 020/200 | Batch 200/981 | Cost: 0.9706\n",
      "Epoch: 020/200 | Batch 400/981 | Cost: 1.0459\n",
      "Epoch: 020/200 | Batch 600/981 | Cost: 1.0227\n",
      "Epoch: 020/200 | Batch 800/981 | Cost: 1.0596\n",
      "Epoch: 020/200 Train Acc.: 39.78% | Validation Acc.: 41.22%\n",
      "Time elapsed: 0.74 min\n",
      "Epoch: 021/200 | Batch 000/981 | Cost: 1.0990\n",
      "Epoch: 021/200 | Batch 200/981 | Cost: 0.9704\n",
      "Epoch: 021/200 | Batch 400/981 | Cost: 1.0458\n",
      "Epoch: 021/200 | Batch 600/981 | Cost: 1.0225\n",
      "Epoch: 021/200 | Batch 800/981 | Cost: 1.0588\n",
      "Epoch: 021/200 Train Acc.: 39.95% | Validation Acc.: 41.49%\n",
      "Time elapsed: 0.78 min\n",
      "Epoch: 022/200 | Batch 000/981 | Cost: 1.0979\n",
      "Epoch: 022/200 | Batch 200/981 | Cost: 0.9703\n",
      "Epoch: 022/200 | Batch 400/981 | Cost: 1.0458\n",
      "Epoch: 022/200 | Batch 600/981 | Cost: 1.0223\n",
      "Epoch: 022/200 | Batch 800/981 | Cost: 1.0581\n",
      "Epoch: 022/200 Train Acc.: 40.18% | Validation Acc.: 41.43%\n",
      "Time elapsed: 0.81 min\n",
      "Epoch: 023/200 | Batch 000/981 | Cost: 1.0969\n",
      "Epoch: 023/200 | Batch 200/981 | Cost: 0.9702\n",
      "Epoch: 023/200 | Batch 400/981 | Cost: 1.0457\n",
      "Epoch: 023/200 | Batch 600/981 | Cost: 1.0221\n",
      "Epoch: 023/200 | Batch 800/981 | Cost: 1.0574\n",
      "Epoch: 023/200 Train Acc.: 40.30% | Validation Acc.: 41.31%\n",
      "Time elapsed: 0.85 min\n",
      "Epoch: 024/200 | Batch 000/981 | Cost: 1.0960\n",
      "Epoch: 024/200 | Batch 200/981 | Cost: 0.9700\n",
      "Epoch: 024/200 | Batch 400/981 | Cost: 1.0456\n",
      "Epoch: 024/200 | Batch 600/981 | Cost: 1.0219\n",
      "Epoch: 024/200 | Batch 800/981 | Cost: 1.0566\n",
      "Epoch: 024/200 Train Acc.: 40.46% | Validation Acc.: 41.52%\n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 025/200 | Batch 000/981 | Cost: 1.0952\n",
      "Epoch: 025/200 | Batch 200/981 | Cost: 0.9700\n",
      "Epoch: 025/200 | Batch 400/981 | Cost: 1.0456\n",
      "Epoch: 025/200 | Batch 600/981 | Cost: 1.0217\n",
      "Epoch: 025/200 | Batch 800/981 | Cost: 1.0559\n",
      "Epoch: 025/200 Train Acc.: 40.55% | Validation Acc.: 41.49%\n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 026/200 | Batch 000/981 | Cost: 1.0945\n",
      "Epoch: 026/200 | Batch 200/981 | Cost: 0.9699\n",
      "Epoch: 026/200 | Batch 400/981 | Cost: 1.0455\n",
      "Epoch: 026/200 | Batch 600/981 | Cost: 1.0214\n",
      "Epoch: 026/200 | Batch 800/981 | Cost: 1.0551\n",
      "Epoch: 026/200 Train Acc.: 40.66% | Validation Acc.: 41.52%\n",
      "Time elapsed: 0.96 min\n",
      "Epoch: 027/200 | Batch 000/981 | Cost: 1.0938\n",
      "Epoch: 027/200 | Batch 200/981 | Cost: 0.9698\n",
      "Epoch: 027/200 | Batch 400/981 | Cost: 1.0455\n",
      "Epoch: 027/200 | Batch 600/981 | Cost: 1.0211\n",
      "Epoch: 027/200 | Batch 800/981 | Cost: 1.0544\n",
      "Epoch: 027/200 Train Acc.: 40.76% | Validation Acc.: 41.46%\n",
      "Time elapsed: 1.00 min\n",
      "Epoch: 028/200 | Batch 000/981 | Cost: 1.0932\n",
      "Epoch: 028/200 | Batch 200/981 | Cost: 0.9698\n",
      "Epoch: 028/200 | Batch 400/981 | Cost: 1.0454\n",
      "Epoch: 028/200 | Batch 600/981 | Cost: 1.0209\n",
      "Epoch: 028/200 | Batch 800/981 | Cost: 1.0536\n",
      "Epoch: 028/200 Train Acc.: 40.86% | Validation Acc.: 41.55%\n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 029/200 | Batch 000/981 | Cost: 1.0927\n",
      "Epoch: 029/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 029/200 | Batch 400/981 | Cost: 1.0453\n",
      "Epoch: 029/200 | Batch 600/981 | Cost: 1.0206\n",
      "Epoch: 029/200 | Batch 800/981 | Cost: 1.0529\n",
      "Epoch: 029/200 Train Acc.: 40.91% | Validation Acc.: 41.49%\n",
      "Time elapsed: 1.08 min\n",
      "Epoch: 030/200 | Batch 000/981 | Cost: 1.0922\n",
      "Epoch: 030/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 030/200 | Batch 400/981 | Cost: 1.0453\n",
      "Epoch: 030/200 | Batch 600/981 | Cost: 1.0203\n",
      "Epoch: 030/200 | Batch 800/981 | Cost: 1.0521\n",
      "Epoch: 030/200 Train Acc.: 41.04% | Validation Acc.: 41.49%\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 031/200 | Batch 000/981 | Cost: 1.0917\n",
      "Epoch: 031/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 031/200 | Batch 400/981 | Cost: 1.0452\n",
      "Epoch: 031/200 | Batch 600/981 | Cost: 1.0200\n",
      "Epoch: 031/200 | Batch 800/981 | Cost: 1.0514\n",
      "Epoch: 031/200 Train Acc.: 41.11% | Validation Acc.: 41.58%\n",
      "Time elapsed: 1.15 min\n",
      "Epoch: 032/200 | Batch 000/981 | Cost: 1.0913\n",
      "Epoch: 032/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 032/200 | Batch 400/981 | Cost: 1.0451\n",
      "Epoch: 032/200 | Batch 600/981 | Cost: 1.0197\n",
      "Epoch: 032/200 | Batch 800/981 | Cost: 1.0506\n",
      "Epoch: 032/200 Train Acc.: 41.15% | Validation Acc.: 41.67%\n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 033/200 | Batch 000/981 | Cost: 1.0910\n",
      "Epoch: 033/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 033/200 | Batch 400/981 | Cost: 1.0450\n",
      "Epoch: 033/200 | Batch 600/981 | Cost: 1.0194\n",
      "Epoch: 033/200 | Batch 800/981 | Cost: 1.0498\n",
      "Epoch: 033/200 Train Acc.: 41.21% | Validation Acc.: 41.70%\n",
      "Time elapsed: 1.22 min\n",
      "Epoch: 034/200 | Batch 000/981 | Cost: 1.0906\n",
      "Epoch: 034/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 034/200 | Batch 400/981 | Cost: 1.0449\n",
      "Epoch: 034/200 | Batch 600/981 | Cost: 1.0190\n",
      "Epoch: 034/200 | Batch 800/981 | Cost: 1.0491\n",
      "Epoch: 034/200 Train Acc.: 41.25% | Validation Acc.: 41.73%\n",
      "Time elapsed: 1.26 min\n",
      "Epoch: 035/200 | Batch 000/981 | Cost: 1.0903\n",
      "Epoch: 035/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 035/200 | Batch 400/981 | Cost: 1.0447\n",
      "Epoch: 035/200 | Batch 600/981 | Cost: 1.0187\n",
      "Epoch: 035/200 | Batch 800/981 | Cost: 1.0483\n",
      "Epoch: 035/200 Train Acc.: 41.36% | Validation Acc.: 41.79%\n",
      "Time elapsed: 1.30 min\n",
      "Epoch: 036/200 | Batch 000/981 | Cost: 1.0900\n",
      "Epoch: 036/200 | Batch 200/981 | Cost: 0.9698\n",
      "Epoch: 036/200 | Batch 400/981 | Cost: 1.0446\n",
      "Epoch: 036/200 | Batch 600/981 | Cost: 1.0184\n",
      "Epoch: 036/200 | Batch 800/981 | Cost: 1.0475\n",
      "Epoch: 036/200 Train Acc.: 41.45% | Validation Acc.: 41.76%\n",
      "Time elapsed: 1.34 min\n",
      "Epoch: 037/200 | Batch 000/981 | Cost: 1.0898\n",
      "Epoch: 037/200 | Batch 200/981 | Cost: 0.9698\n",
      "Epoch: 037/200 | Batch 400/981 | Cost: 1.0445\n",
      "Epoch: 037/200 | Batch 600/981 | Cost: 1.0180\n",
      "Epoch: 037/200 | Batch 800/981 | Cost: 1.0467\n",
      "Epoch: 037/200 Train Acc.: 41.48% | Validation Acc.: 41.64%\n",
      "Time elapsed: 1.37 min\n",
      "Epoch: 038/200 | Batch 000/981 | Cost: 1.0895\n",
      "Epoch: 038/200 | Batch 200/981 | Cost: 0.9699\n",
      "Epoch: 038/200 | Batch 400/981 | Cost: 1.0443\n",
      "Epoch: 038/200 | Batch 600/981 | Cost: 1.0177\n",
      "Epoch: 038/200 | Batch 800/981 | Cost: 1.0459\n",
      "Epoch: 038/200 Train Acc.: 41.52% | Validation Acc.: 41.61%\n",
      "Time elapsed: 1.41 min\n",
      "Epoch: 039/200 | Batch 000/981 | Cost: 1.0893\n",
      "Epoch: 039/200 | Batch 200/981 | Cost: 0.9699\n",
      "Epoch: 039/200 | Batch 400/981 | Cost: 1.0442\n",
      "Epoch: 039/200 | Batch 600/981 | Cost: 1.0173\n",
      "Epoch: 039/200 | Batch 800/981 | Cost: 1.0452\n",
      "Epoch: 039/200 Train Acc.: 41.56% | Validation Acc.: 41.61%\n",
      "Time elapsed: 1.45 min\n",
      "Epoch: 040/200 | Batch 000/981 | Cost: 1.0890\n",
      "Epoch: 040/200 | Batch 200/981 | Cost: 0.9700\n",
      "Epoch: 040/200 | Batch 400/981 | Cost: 1.0440\n",
      "Epoch: 040/200 | Batch 600/981 | Cost: 1.0170\n",
      "Epoch: 040/200 | Batch 800/981 | Cost: 1.0444\n",
      "Epoch: 040/200 Train Acc.: 41.60% | Validation Acc.: 41.49%\n",
      "Time elapsed: 1.49 min\n",
      "Epoch: 041/200 | Batch 000/981 | Cost: 1.0888\n",
      "Epoch: 041/200 | Batch 200/981 | Cost: 0.9700\n",
      "Epoch: 041/200 | Batch 400/981 | Cost: 1.0438\n",
      "Epoch: 041/200 | Batch 600/981 | Cost: 1.0166\n",
      "Epoch: 041/200 | Batch 800/981 | Cost: 1.0436\n",
      "Epoch: 041/200 Train Acc.: 41.64% | Validation Acc.: 41.55%\n",
      "Time elapsed: 1.52 min\n",
      "Epoch: 042/200 | Batch 000/981 | Cost: 1.0885\n",
      "Epoch: 042/200 | Batch 200/981 | Cost: 0.9701\n",
      "Epoch: 042/200 | Batch 400/981 | Cost: 1.0436\n",
      "Epoch: 042/200 | Batch 600/981 | Cost: 1.0162\n",
      "Epoch: 042/200 | Batch 800/981 | Cost: 1.0428\n",
      "Epoch: 042/200 Train Acc.: 41.66% | Validation Acc.: 41.64%\n",
      "Time elapsed: 1.56 min\n",
      "Epoch: 043/200 | Batch 000/981 | Cost: 1.0883\n",
      "Epoch: 043/200 | Batch 200/981 | Cost: 0.9702\n",
      "Epoch: 043/200 | Batch 400/981 | Cost: 1.0434\n",
      "Epoch: 043/200 | Batch 600/981 | Cost: 1.0158\n",
      "Epoch: 043/200 | Batch 800/981 | Cost: 1.0420\n",
      "Epoch: 043/200 Train Acc.: 41.65% | Validation Acc.: 41.79%\n",
      "Time elapsed: 1.60 min\n",
      "Epoch: 044/200 | Batch 000/981 | Cost: 1.0881\n",
      "Epoch: 044/200 | Batch 200/981 | Cost: 0.9703\n",
      "Epoch: 044/200 | Batch 400/981 | Cost: 1.0432\n",
      "Epoch: 044/200 | Batch 600/981 | Cost: 1.0154\n",
      "Epoch: 044/200 | Batch 800/981 | Cost: 1.0412\n",
      "Epoch: 044/200 Train Acc.: 41.65% | Validation Acc.: 41.88%\n",
      "Time elapsed: 1.64 min\n",
      "Epoch: 045/200 | Batch 000/981 | Cost: 1.0878\n",
      "Epoch: 045/200 | Batch 200/981 | Cost: 0.9703\n",
      "Epoch: 045/200 | Batch 400/981 | Cost: 1.0430\n",
      "Epoch: 045/200 | Batch 600/981 | Cost: 1.0150\n",
      "Epoch: 045/200 | Batch 800/981 | Cost: 1.0405\n",
      "Epoch: 045/200 Train Acc.: 41.69% | Validation Acc.: 41.79%\n",
      "Time elapsed: 1.67 min\n",
      "Epoch: 046/200 | Batch 000/981 | Cost: 1.0875\n",
      "Epoch: 046/200 | Batch 200/981 | Cost: 0.9704\n",
      "Epoch: 046/200 | Batch 400/981 | Cost: 1.0428\n",
      "Epoch: 046/200 | Batch 600/981 | Cost: 1.0146\n",
      "Epoch: 046/200 | Batch 800/981 | Cost: 1.0397\n",
      "Epoch: 046/200 Train Acc.: 41.75% | Validation Acc.: 41.79%\n",
      "Time elapsed: 1.71 min\n",
      "Epoch: 047/200 | Batch 000/981 | Cost: 1.0872\n",
      "Epoch: 047/200 | Batch 200/981 | Cost: 0.9705\n",
      "Epoch: 047/200 | Batch 400/981 | Cost: 1.0425\n",
      "Epoch: 047/200 | Batch 600/981 | Cost: 1.0142\n",
      "Epoch: 047/200 | Batch 800/981 | Cost: 1.0389\n",
      "Epoch: 047/200 Train Acc.: 41.78% | Validation Acc.: 41.79%\n",
      "Time elapsed: 1.75 min\n",
      "Epoch: 048/200 | Batch 000/981 | Cost: 1.0869\n",
      "Epoch: 048/200 | Batch 200/981 | Cost: 0.9705\n",
      "Epoch: 048/200 | Batch 400/981 | Cost: 1.0423\n",
      "Epoch: 048/200 | Batch 600/981 | Cost: 1.0138\n",
      "Epoch: 048/200 | Batch 800/981 | Cost: 1.0381\n",
      "Epoch: 048/200 Train Acc.: 41.82% | Validation Acc.: 41.73%\n",
      "Time elapsed: 1.79 min\n",
      "Epoch: 049/200 | Batch 000/981 | Cost: 1.0866\n",
      "Epoch: 049/200 | Batch 200/981 | Cost: 0.9706\n",
      "Epoch: 049/200 | Batch 400/981 | Cost: 1.0420\n",
      "Epoch: 049/200 | Batch 600/981 | Cost: 1.0134\n",
      "Epoch: 049/200 | Batch 800/981 | Cost: 1.0373\n",
      "Epoch: 049/200 Train Acc.: 41.87% | Validation Acc.: 41.76%\n",
      "Time elapsed: 1.82 min\n",
      "Epoch: 050/200 | Batch 000/981 | Cost: 1.0863\n",
      "Epoch: 050/200 | Batch 200/981 | Cost: 0.9706\n",
      "Epoch: 050/200 | Batch 400/981 | Cost: 1.0417\n",
      "Epoch: 050/200 | Batch 600/981 | Cost: 1.0130\n",
      "Epoch: 050/200 | Batch 800/981 | Cost: 1.0366\n",
      "Epoch: 050/200 Train Acc.: 41.94% | Validation Acc.: 41.82%\n",
      "Time elapsed: 1.86 min\n",
      "Epoch: 051/200 | Batch 000/981 | Cost: 1.0860\n",
      "Epoch: 051/200 | Batch 200/981 | Cost: 0.9707\n",
      "Epoch: 051/200 | Batch 400/981 | Cost: 1.0415\n",
      "Epoch: 051/200 | Batch 600/981 | Cost: 1.0125\n",
      "Epoch: 051/200 | Batch 800/981 | Cost: 1.0358\n",
      "Epoch: 051/200 Train Acc.: 41.96% | Validation Acc.: 41.73%\n",
      "Time elapsed: 1.90 min\n",
      "Epoch: 052/200 | Batch 000/981 | Cost: 1.0856\n",
      "Epoch: 052/200 | Batch 200/981 | Cost: 0.9707\n",
      "Epoch: 052/200 | Batch 400/981 | Cost: 1.0412\n",
      "Epoch: 052/200 | Batch 600/981 | Cost: 1.0121\n",
      "Epoch: 052/200 | Batch 800/981 | Cost: 1.0350\n",
      "Epoch: 052/200 Train Acc.: 42.00% | Validation Acc.: 41.91%\n",
      "Time elapsed: 1.93 min\n",
      "Epoch: 053/200 | Batch 000/981 | Cost: 1.0853\n",
      "Epoch: 053/200 | Batch 200/981 | Cost: 0.9707\n",
      "Epoch: 053/200 | Batch 400/981 | Cost: 1.0408\n",
      "Epoch: 053/200 | Batch 600/981 | Cost: 1.0117\n",
      "Epoch: 053/200 | Batch 800/981 | Cost: 1.0342\n",
      "Epoch: 053/200 Train Acc.: 42.03% | Validation Acc.: 41.85%\n",
      "Time elapsed: 1.97 min\n",
      "Epoch: 054/200 | Batch 000/981 | Cost: 1.0849\n",
      "Epoch: 054/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 054/200 | Batch 400/981 | Cost: 1.0405\n",
      "Epoch: 054/200 | Batch 600/981 | Cost: 1.0112\n",
      "Epoch: 054/200 | Batch 800/981 | Cost: 1.0334\n",
      "Epoch: 054/200 Train Acc.: 42.07% | Validation Acc.: 41.94%\n",
      "Time elapsed: 2.01 min\n",
      "Epoch: 055/200 | Batch 000/981 | Cost: 1.0845\n",
      "Epoch: 055/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 055/200 | Batch 400/981 | Cost: 1.0402\n",
      "Epoch: 055/200 | Batch 600/981 | Cost: 1.0108\n",
      "Epoch: 055/200 | Batch 800/981 | Cost: 1.0327\n",
      "Epoch: 055/200 Train Acc.: 42.08% | Validation Acc.: 42.00%\n",
      "Time elapsed: 2.05 min\n",
      "Epoch: 056/200 | Batch 000/981 | Cost: 1.0841\n",
      "Epoch: 056/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 056/200 | Batch 400/981 | Cost: 1.0398\n",
      "Epoch: 056/200 | Batch 600/981 | Cost: 1.0103\n",
      "Epoch: 056/200 | Batch 800/981 | Cost: 1.0319\n",
      "Epoch: 056/200 Train Acc.: 42.11% | Validation Acc.: 42.00%\n",
      "Time elapsed: 2.08 min\n",
      "Epoch: 057/200 | Batch 000/981 | Cost: 1.0838\n",
      "Epoch: 057/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 057/200 | Batch 400/981 | Cost: 1.0394\n",
      "Epoch: 057/200 | Batch 600/981 | Cost: 1.0099\n",
      "Epoch: 057/200 | Batch 800/981 | Cost: 1.0311\n",
      "Epoch: 057/200 Train Acc.: 42.19% | Validation Acc.: 41.88%\n",
      "Time elapsed: 2.12 min\n",
      "Epoch: 058/200 | Batch 000/981 | Cost: 1.0834\n",
      "Epoch: 058/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 058/200 | Batch 400/981 | Cost: 1.0390\n",
      "Epoch: 058/200 | Batch 600/981 | Cost: 1.0094\n",
      "Epoch: 058/200 | Batch 800/981 | Cost: 1.0302\n",
      "Epoch: 058/200 Train Acc.: 42.22% | Validation Acc.: 41.88%\n",
      "Time elapsed: 2.16 min\n",
      "Epoch: 059/200 | Batch 000/981 | Cost: 1.0830\n",
      "Epoch: 059/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 059/200 | Batch 400/981 | Cost: 1.0386\n",
      "Epoch: 059/200 | Batch 600/981 | Cost: 1.0089\n",
      "Epoch: 059/200 | Batch 800/981 | Cost: 1.0294\n",
      "Epoch: 059/200 Train Acc.: 42.26% | Validation Acc.: 41.94%\n",
      "Time elapsed: 2.19 min\n",
      "Epoch: 060/200 | Batch 000/981 | Cost: 1.0826\n",
      "Epoch: 060/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 060/200 | Batch 400/981 | Cost: 1.0382\n",
      "Epoch: 060/200 | Batch 600/981 | Cost: 1.0085\n",
      "Epoch: 060/200 | Batch 800/981 | Cost: 1.0286\n",
      "Epoch: 060/200 Train Acc.: 42.32% | Validation Acc.: 41.91%\n",
      "Time elapsed: 2.23 min\n",
      "Epoch: 061/200 | Batch 000/981 | Cost: 1.0822\n",
      "Epoch: 061/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 061/200 | Batch 400/981 | Cost: 1.0377\n",
      "Epoch: 061/200 | Batch 600/981 | Cost: 1.0080\n",
      "Epoch: 061/200 | Batch 800/981 | Cost: 1.0278\n",
      "Epoch: 061/200 Train Acc.: 42.34% | Validation Acc.: 42.00%\n",
      "Time elapsed: 2.27 min\n",
      "Epoch: 062/200 | Batch 000/981 | Cost: 1.0818\n",
      "Epoch: 062/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 062/200 | Batch 400/981 | Cost: 1.0373\n",
      "Epoch: 062/200 | Batch 600/981 | Cost: 1.0075\n",
      "Epoch: 062/200 | Batch 800/981 | Cost: 1.0270\n",
      "Epoch: 062/200 Train Acc.: 42.37% | Validation Acc.: 41.85%\n",
      "Time elapsed: 2.31 min\n",
      "Epoch: 063/200 | Batch 000/981 | Cost: 1.0815\n",
      "Epoch: 063/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 063/200 | Batch 400/981 | Cost: 1.0368\n",
      "Epoch: 063/200 | Batch 600/981 | Cost: 1.0070\n",
      "Epoch: 063/200 | Batch 800/981 | Cost: 1.0261\n",
      "Epoch: 063/200 Train Acc.: 42.42% | Validation Acc.: 41.85%\n",
      "Time elapsed: 2.34 min\n",
      "Epoch: 064/200 | Batch 000/981 | Cost: 1.0811\n",
      "Epoch: 064/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 064/200 | Batch 400/981 | Cost: 1.0363\n",
      "Epoch: 064/200 | Batch 600/981 | Cost: 1.0065\n",
      "Epoch: 064/200 | Batch 800/981 | Cost: 1.0253\n",
      "Epoch: 064/200 Train Acc.: 42.47% | Validation Acc.: 41.79%\n",
      "Time elapsed: 2.38 min\n",
      "Epoch: 065/200 | Batch 000/981 | Cost: 1.0807\n",
      "Epoch: 065/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 065/200 | Batch 400/981 | Cost: 1.0358\n",
      "Epoch: 065/200 | Batch 600/981 | Cost: 1.0060\n",
      "Epoch: 065/200 | Batch 800/981 | Cost: 1.0244\n",
      "Epoch: 065/200 Train Acc.: 42.49% | Validation Acc.: 41.73%\n",
      "Time elapsed: 2.42 min\n",
      "Epoch: 066/200 | Batch 000/981 | Cost: 1.0804\n",
      "Epoch: 066/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 066/200 | Batch 400/981 | Cost: 1.0352\n",
      "Epoch: 066/200 | Batch 600/981 | Cost: 1.0055\n",
      "Epoch: 066/200 | Batch 800/981 | Cost: 1.0236\n",
      "Epoch: 066/200 Train Acc.: 42.55% | Validation Acc.: 41.79%\n",
      "Time elapsed: 2.45 min\n",
      "Epoch: 067/200 | Batch 000/981 | Cost: 1.0800\n",
      "Epoch: 067/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 067/200 | Batch 400/981 | Cost: 1.0347\n",
      "Epoch: 067/200 | Batch 600/981 | Cost: 1.0050\n",
      "Epoch: 067/200 | Batch 800/981 | Cost: 1.0228\n",
      "Epoch: 067/200 Train Acc.: 42.59% | Validation Acc.: 41.79%\n",
      "Time elapsed: 2.49 min\n",
      "Epoch: 068/200 | Batch 000/981 | Cost: 1.0797\n",
      "Epoch: 068/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 068/200 | Batch 400/981 | Cost: 1.0341\n",
      "Epoch: 068/200 | Batch 600/981 | Cost: 1.0045\n",
      "Epoch: 068/200 | Batch 800/981 | Cost: 1.0219\n",
      "Epoch: 068/200 Train Acc.: 42.67% | Validation Acc.: 41.88%\n",
      "Time elapsed: 2.53 min\n",
      "Epoch: 069/200 | Batch 000/981 | Cost: 1.0793\n",
      "Epoch: 069/200 | Batch 200/981 | Cost: 0.9709\n",
      "Epoch: 069/200 | Batch 400/981 | Cost: 1.0335\n",
      "Epoch: 069/200 | Batch 600/981 | Cost: 1.0039\n",
      "Epoch: 069/200 | Batch 800/981 | Cost: 1.0211\n",
      "Epoch: 069/200 Train Acc.: 42.72% | Validation Acc.: 41.79%\n",
      "Time elapsed: 2.57 min\n",
      "Epoch: 070/200 | Batch 000/981 | Cost: 1.0790\n",
      "Epoch: 070/200 | Batch 200/981 | Cost: 0.9709\n",
      "Epoch: 070/200 | Batch 400/981 | Cost: 1.0330\n",
      "Epoch: 070/200 | Batch 600/981 | Cost: 1.0034\n",
      "Epoch: 070/200 | Batch 800/981 | Cost: 1.0202\n",
      "Epoch: 070/200 Train Acc.: 42.76% | Validation Acc.: 41.82%\n",
      "Time elapsed: 2.60 min\n",
      "Epoch: 071/200 | Batch 000/981 | Cost: 1.0787\n",
      "Epoch: 071/200 | Batch 200/981 | Cost: 0.9709\n",
      "Epoch: 071/200 | Batch 400/981 | Cost: 1.0324\n",
      "Epoch: 071/200 | Batch 600/981 | Cost: 1.0028\n",
      "Epoch: 071/200 | Batch 800/981 | Cost: 1.0194\n",
      "Epoch: 071/200 Train Acc.: 42.81% | Validation Acc.: 41.82%\n",
      "Time elapsed: 2.64 min\n",
      "Epoch: 072/200 | Batch 000/981 | Cost: 1.0784\n",
      "Epoch: 072/200 | Batch 200/981 | Cost: 0.9710\n",
      "Epoch: 072/200 | Batch 400/981 | Cost: 1.0317\n",
      "Epoch: 072/200 | Batch 600/981 | Cost: 1.0023\n",
      "Epoch: 072/200 | Batch 800/981 | Cost: 1.0186\n",
      "Epoch: 072/200 Train Acc.: 42.85% | Validation Acc.: 41.91%\n",
      "Time elapsed: 2.68 min\n",
      "Epoch: 073/200 | Batch 000/981 | Cost: 1.0781\n",
      "Epoch: 073/200 | Batch 200/981 | Cost: 0.9710\n",
      "Epoch: 073/200 | Batch 400/981 | Cost: 1.0311\n",
      "Epoch: 073/200 | Batch 600/981 | Cost: 1.0017\n",
      "Epoch: 073/200 | Batch 800/981 | Cost: 1.0177\n",
      "Epoch: 073/200 Train Acc.: 42.89% | Validation Acc.: 41.91%\n",
      "Time elapsed: 2.72 min\n",
      "Epoch: 074/200 | Batch 000/981 | Cost: 1.0778\n",
      "Epoch: 074/200 | Batch 200/981 | Cost: 0.9711\n",
      "Epoch: 074/200 | Batch 400/981 | Cost: 1.0305\n",
      "Epoch: 074/200 | Batch 600/981 | Cost: 1.0011\n",
      "Epoch: 074/200 | Batch 800/981 | Cost: 1.0169\n",
      "Epoch: 074/200 Train Acc.: 42.95% | Validation Acc.: 41.97%\n",
      "Time elapsed: 2.75 min\n",
      "Epoch: 075/200 | Batch 000/981 | Cost: 1.0775\n",
      "Epoch: 075/200 | Batch 200/981 | Cost: 0.9711\n",
      "Epoch: 075/200 | Batch 400/981 | Cost: 1.0298\n",
      "Epoch: 075/200 | Batch 600/981 | Cost: 1.0006\n",
      "Epoch: 075/200 | Batch 800/981 | Cost: 1.0161\n",
      "Epoch: 075/200 Train Acc.: 43.00% | Validation Acc.: 41.97%\n",
      "Time elapsed: 2.79 min\n",
      "Epoch: 076/200 | Batch 000/981 | Cost: 1.0773\n",
      "Epoch: 076/200 | Batch 200/981 | Cost: 0.9712\n",
      "Epoch: 076/200 | Batch 400/981 | Cost: 1.0292\n",
      "Epoch: 076/200 | Batch 600/981 | Cost: 1.0000\n",
      "Epoch: 076/200 | Batch 800/981 | Cost: 1.0154\n",
      "Epoch: 076/200 Train Acc.: 43.03% | Validation Acc.: 42.04%\n",
      "Time elapsed: 2.83 min\n",
      "Epoch: 077/200 | Batch 000/981 | Cost: 1.0770\n",
      "Epoch: 077/200 | Batch 200/981 | Cost: 0.9713\n",
      "Epoch: 077/200 | Batch 400/981 | Cost: 1.0285\n",
      "Epoch: 077/200 | Batch 600/981 | Cost: 0.9994\n",
      "Epoch: 077/200 | Batch 800/981 | Cost: 1.0146\n",
      "Epoch: 077/200 Train Acc.: 43.07% | Validation Acc.: 42.16%\n",
      "Time elapsed: 2.87 min\n",
      "Epoch: 078/200 | Batch 000/981 | Cost: 1.0767\n",
      "Epoch: 078/200 | Batch 200/981 | Cost: 0.9714\n",
      "Epoch: 078/200 | Batch 400/981 | Cost: 1.0278\n",
      "Epoch: 078/200 | Batch 600/981 | Cost: 0.9988\n",
      "Epoch: 078/200 | Batch 800/981 | Cost: 1.0138\n",
      "Epoch: 078/200 Train Acc.: 43.12% | Validation Acc.: 42.13%\n",
      "Time elapsed: 2.90 min\n",
      "Epoch: 079/200 | Batch 000/981 | Cost: 1.0765\n",
      "Epoch: 079/200 | Batch 200/981 | Cost: 0.9715\n",
      "Epoch: 079/200 | Batch 400/981 | Cost: 1.0272\n",
      "Epoch: 079/200 | Batch 600/981 | Cost: 0.9982\n",
      "Epoch: 079/200 | Batch 800/981 | Cost: 1.0131\n",
      "Epoch: 079/200 Train Acc.: 43.19% | Validation Acc.: 42.04%\n",
      "Time elapsed: 2.94 min\n",
      "Epoch: 080/200 | Batch 000/981 | Cost: 1.0762\n",
      "Epoch: 080/200 | Batch 200/981 | Cost: 0.9716\n",
      "Epoch: 080/200 | Batch 400/981 | Cost: 1.0265\n",
      "Epoch: 080/200 | Batch 600/981 | Cost: 0.9976\n",
      "Epoch: 080/200 | Batch 800/981 | Cost: 1.0124\n",
      "Epoch: 080/200 Train Acc.: 43.22% | Validation Acc.: 42.13%\n",
      "Time elapsed: 2.98 min\n",
      "Epoch: 081/200 | Batch 000/981 | Cost: 1.0760\n",
      "Epoch: 081/200 | Batch 200/981 | Cost: 0.9717\n",
      "Epoch: 081/200 | Batch 400/981 | Cost: 1.0258\n",
      "Epoch: 081/200 | Batch 600/981 | Cost: 0.9970\n",
      "Epoch: 081/200 | Batch 800/981 | Cost: 1.0117\n",
      "Epoch: 081/200 Train Acc.: 43.30% | Validation Acc.: 42.07%\n",
      "Time elapsed: 3.01 min\n",
      "Epoch: 082/200 | Batch 000/981 | Cost: 1.0758\n",
      "Epoch: 082/200 | Batch 200/981 | Cost: 0.9718\n",
      "Epoch: 082/200 | Batch 400/981 | Cost: 1.0250\n",
      "Epoch: 082/200 | Batch 600/981 | Cost: 0.9964\n",
      "Epoch: 082/200 | Batch 800/981 | Cost: 1.0110\n",
      "Epoch: 082/200 Train Acc.: 43.33% | Validation Acc.: 42.07%\n",
      "Time elapsed: 3.05 min\n",
      "Epoch: 083/200 | Batch 000/981 | Cost: 1.0755\n",
      "Epoch: 083/200 | Batch 200/981 | Cost: 0.9719\n",
      "Epoch: 083/200 | Batch 400/981 | Cost: 1.0243\n",
      "Epoch: 083/200 | Batch 600/981 | Cost: 0.9959\n",
      "Epoch: 083/200 | Batch 800/981 | Cost: 1.0104\n",
      "Epoch: 083/200 Train Acc.: 43.36% | Validation Acc.: 42.13%\n",
      "Time elapsed: 3.09 min\n",
      "Epoch: 084/200 | Batch 000/981 | Cost: 1.0753\n",
      "Epoch: 084/200 | Batch 200/981 | Cost: 0.9720\n",
      "Epoch: 084/200 | Batch 400/981 | Cost: 1.0236\n",
      "Epoch: 084/200 | Batch 600/981 | Cost: 0.9953\n",
      "Epoch: 084/200 | Batch 800/981 | Cost: 1.0097\n",
      "Epoch: 084/200 Train Acc.: 43.42% | Validation Acc.: 42.07%\n",
      "Time elapsed: 3.12 min\n",
      "Epoch: 085/200 | Batch 000/981 | Cost: 1.0751\n",
      "Epoch: 085/200 | Batch 200/981 | Cost: 0.9721\n",
      "Epoch: 085/200 | Batch 400/981 | Cost: 1.0229\n",
      "Epoch: 085/200 | Batch 600/981 | Cost: 0.9947\n",
      "Epoch: 085/200 | Batch 800/981 | Cost: 1.0091\n",
      "Epoch: 085/200 Train Acc.: 43.48% | Validation Acc.: 42.19%\n",
      "Time elapsed: 3.16 min\n",
      "Epoch: 086/200 | Batch 000/981 | Cost: 1.0748\n",
      "Epoch: 086/200 | Batch 200/981 | Cost: 0.9722\n",
      "Epoch: 086/200 | Batch 400/981 | Cost: 1.0221\n",
      "Epoch: 086/200 | Batch 600/981 | Cost: 0.9941\n",
      "Epoch: 086/200 | Batch 800/981 | Cost: 1.0085\n",
      "Epoch: 086/200 Train Acc.: 43.51% | Validation Acc.: 42.19%\n",
      "Time elapsed: 3.20 min\n",
      "Epoch: 087/200 | Batch 000/981 | Cost: 1.0746\n",
      "Epoch: 087/200 | Batch 200/981 | Cost: 0.9723\n",
      "Epoch: 087/200 | Batch 400/981 | Cost: 1.0214\n",
      "Epoch: 087/200 | Batch 600/981 | Cost: 0.9935\n",
      "Epoch: 087/200 | Batch 800/981 | Cost: 1.0079\n",
      "Epoch: 087/200 Train Acc.: 43.52% | Validation Acc.: 42.04%\n",
      "Time elapsed: 3.24 min\n",
      "Epoch: 088/200 | Batch 000/981 | Cost: 1.0744\n",
      "Epoch: 088/200 | Batch 200/981 | Cost: 0.9724\n",
      "Epoch: 088/200 | Batch 400/981 | Cost: 1.0206\n",
      "Epoch: 088/200 | Batch 600/981 | Cost: 0.9929\n",
      "Epoch: 088/200 | Batch 800/981 | Cost: 1.0073\n",
      "Epoch: 088/200 Train Acc.: 43.57% | Validation Acc.: 42.10%\n",
      "Time elapsed: 3.27 min\n",
      "Epoch: 089/200 | Batch 000/981 | Cost: 1.0742\n",
      "Epoch: 089/200 | Batch 200/981 | Cost: 0.9725\n",
      "Epoch: 089/200 | Batch 400/981 | Cost: 1.0198\n",
      "Epoch: 089/200 | Batch 600/981 | Cost: 0.9924\n",
      "Epoch: 089/200 | Batch 800/981 | Cost: 1.0068\n",
      "Epoch: 089/200 Train Acc.: 43.58% | Validation Acc.: 42.04%\n",
      "Time elapsed: 3.31 min\n",
      "Epoch: 090/200 | Batch 000/981 | Cost: 1.0740\n",
      "Epoch: 090/200 | Batch 200/981 | Cost: 0.9726\n",
      "Epoch: 090/200 | Batch 400/981 | Cost: 1.0190\n",
      "Epoch: 090/200 | Batch 600/981 | Cost: 0.9918\n",
      "Epoch: 090/200 | Batch 800/981 | Cost: 1.0062\n",
      "Epoch: 090/200 Train Acc.: 43.63% | Validation Acc.: 42.04%\n",
      "Time elapsed: 3.35 min\n",
      "Epoch: 091/200 | Batch 000/981 | Cost: 1.0738\n",
      "Epoch: 091/200 | Batch 200/981 | Cost: 0.9727\n",
      "Epoch: 091/200 | Batch 400/981 | Cost: 1.0182\n",
      "Epoch: 091/200 | Batch 600/981 | Cost: 0.9912\n",
      "Epoch: 091/200 | Batch 800/981 | Cost: 1.0057\n",
      "Epoch: 091/200 Train Acc.: 43.65% | Validation Acc.: 41.94%\n",
      "Time elapsed: 3.39 min\n",
      "Epoch: 092/200 | Batch 000/981 | Cost: 1.0736\n",
      "Epoch: 092/200 | Batch 200/981 | Cost: 0.9728\n",
      "Epoch: 092/200 | Batch 400/981 | Cost: 1.0174\n",
      "Epoch: 092/200 | Batch 600/981 | Cost: 0.9907\n",
      "Epoch: 092/200 | Batch 800/981 | Cost: 1.0051\n",
      "Epoch: 092/200 Train Acc.: 43.70% | Validation Acc.: 41.94%\n",
      "Time elapsed: 3.42 min\n",
      "Epoch: 093/200 | Batch 000/981 | Cost: 1.0734\n",
      "Epoch: 093/200 | Batch 200/981 | Cost: 0.9728\n",
      "Epoch: 093/200 | Batch 400/981 | Cost: 1.0166\n",
      "Epoch: 093/200 | Batch 600/981 | Cost: 0.9901\n",
      "Epoch: 093/200 | Batch 800/981 | Cost: 1.0046\n",
      "Epoch: 093/200 Train Acc.: 43.73% | Validation Acc.: 42.07%\n",
      "Time elapsed: 3.46 min\n",
      "Epoch: 094/200 | Batch 000/981 | Cost: 1.0731\n",
      "Epoch: 094/200 | Batch 200/981 | Cost: 0.9729\n",
      "Epoch: 094/200 | Batch 400/981 | Cost: 1.0158\n",
      "Epoch: 094/200 | Batch 600/981 | Cost: 0.9896\n",
      "Epoch: 094/200 | Batch 800/981 | Cost: 1.0041\n",
      "Epoch: 094/200 Train Acc.: 43.75% | Validation Acc.: 42.16%\n",
      "Time elapsed: 3.50 min\n",
      "Epoch: 095/200 | Batch 000/981 | Cost: 1.0729\n",
      "Epoch: 095/200 | Batch 200/981 | Cost: 0.9729\n",
      "Epoch: 095/200 | Batch 400/981 | Cost: 1.0149\n",
      "Epoch: 095/200 | Batch 600/981 | Cost: 0.9890\n",
      "Epoch: 095/200 | Batch 800/981 | Cost: 1.0036\n",
      "Epoch: 095/200 Train Acc.: 43.75% | Validation Acc.: 42.16%\n",
      "Time elapsed: 3.54 min\n",
      "Epoch: 096/200 | Batch 000/981 | Cost: 1.0727\n",
      "Epoch: 096/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 096/200 | Batch 400/981 | Cost: 1.0141\n",
      "Epoch: 096/200 | Batch 600/981 | Cost: 0.9885\n",
      "Epoch: 096/200 | Batch 800/981 | Cost: 1.0031\n",
      "Epoch: 096/200 Train Acc.: 43.75% | Validation Acc.: 42.19%\n",
      "Time elapsed: 3.57 min\n",
      "Epoch: 097/200 | Batch 000/981 | Cost: 1.0725\n",
      "Epoch: 097/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 097/200 | Batch 400/981 | Cost: 1.0133\n",
      "Epoch: 097/200 | Batch 600/981 | Cost: 0.9879\n",
      "Epoch: 097/200 | Batch 800/981 | Cost: 1.0026\n",
      "Epoch: 097/200 Train Acc.: 43.79% | Validation Acc.: 42.13%\n",
      "Time elapsed: 3.61 min\n",
      "Epoch: 098/200 | Batch 000/981 | Cost: 1.0723\n",
      "Epoch: 098/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 098/200 | Batch 400/981 | Cost: 1.0124\n",
      "Epoch: 098/200 | Batch 600/981 | Cost: 0.9874\n",
      "Epoch: 098/200 | Batch 800/981 | Cost: 1.0021\n",
      "Epoch: 098/200 Train Acc.: 43.80% | Validation Acc.: 42.10%\n",
      "Time elapsed: 3.65 min\n",
      "Epoch: 099/200 | Batch 000/981 | Cost: 1.0721\n",
      "Epoch: 099/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 099/200 | Batch 400/981 | Cost: 1.0115\n",
      "Epoch: 099/200 | Batch 600/981 | Cost: 0.9868\n",
      "Epoch: 099/200 | Batch 800/981 | Cost: 1.0017\n",
      "Epoch: 099/200 Train Acc.: 43.79% | Validation Acc.: 42.10%\n",
      "Time elapsed: 3.69 min\n",
      "Epoch: 100/200 | Batch 000/981 | Cost: 1.0719\n",
      "Epoch: 100/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 100/200 | Batch 400/981 | Cost: 1.0106\n",
      "Epoch: 100/200 | Batch 600/981 | Cost: 0.9863\n",
      "Epoch: 100/200 | Batch 800/981 | Cost: 1.0012\n",
      "Epoch: 100/200 Train Acc.: 43.83% | Validation Acc.: 42.10%\n",
      "Time elapsed: 3.72 min\n",
      "Epoch: 101/200 | Batch 000/981 | Cost: 1.0717\n",
      "Epoch: 101/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 101/200 | Batch 400/981 | Cost: 1.0097\n",
      "Epoch: 101/200 | Batch 600/981 | Cost: 0.9858\n",
      "Epoch: 101/200 | Batch 800/981 | Cost: 1.0007\n",
      "Epoch: 101/200 Train Acc.: 43.83% | Validation Acc.: 42.04%\n",
      "Time elapsed: 3.76 min\n",
      "Epoch: 102/200 | Batch 000/981 | Cost: 1.0715\n",
      "Epoch: 102/200 | Batch 200/981 | Cost: 0.9730\n",
      "Epoch: 102/200 | Batch 400/981 | Cost: 1.0088\n",
      "Epoch: 102/200 | Batch 600/981 | Cost: 0.9853\n",
      "Epoch: 102/200 | Batch 800/981 | Cost: 1.0002\n",
      "Epoch: 102/200 Train Acc.: 43.85% | Validation Acc.: 41.97%\n",
      "Time elapsed: 3.80 min\n",
      "Epoch: 103/200 | Batch 000/981 | Cost: 1.0713\n",
      "Epoch: 103/200 | Batch 200/981 | Cost: 0.9729\n",
      "Epoch: 103/200 | Batch 400/981 | Cost: 1.0079\n",
      "Epoch: 103/200 | Batch 600/981 | Cost: 0.9847\n",
      "Epoch: 103/200 | Batch 800/981 | Cost: 0.9997\n",
      "Epoch: 103/200 Train Acc.: 43.88% | Validation Acc.: 41.94%\n",
      "Time elapsed: 3.84 min\n",
      "Epoch: 104/200 | Batch 000/981 | Cost: 1.0711\n",
      "Epoch: 104/200 | Batch 200/981 | Cost: 0.9728\n",
      "Epoch: 104/200 | Batch 400/981 | Cost: 1.0070\n",
      "Epoch: 104/200 | Batch 600/981 | Cost: 0.9842\n",
      "Epoch: 104/200 | Batch 800/981 | Cost: 0.9992\n",
      "Epoch: 104/200 Train Acc.: 43.91% | Validation Acc.: 41.97%\n",
      "Time elapsed: 3.87 min\n",
      "Epoch: 105/200 | Batch 000/981 | Cost: 1.0709\n",
      "Epoch: 105/200 | Batch 200/981 | Cost: 0.9727\n",
      "Epoch: 105/200 | Batch 400/981 | Cost: 1.0061\n",
      "Epoch: 105/200 | Batch 600/981 | Cost: 0.9837\n",
      "Epoch: 105/200 | Batch 800/981 | Cost: 0.9987\n",
      "Epoch: 105/200 Train Acc.: 43.93% | Validation Acc.: 41.97%\n",
      "Time elapsed: 3.91 min\n",
      "Epoch: 106/200 | Batch 000/981 | Cost: 1.0706\n",
      "Epoch: 106/200 | Batch 200/981 | Cost: 0.9726\n",
      "Epoch: 106/200 | Batch 400/981 | Cost: 1.0052\n",
      "Epoch: 106/200 | Batch 600/981 | Cost: 0.9832\n",
      "Epoch: 106/200 | Batch 800/981 | Cost: 0.9982\n",
      "Epoch: 106/200 Train Acc.: 43.95% | Validation Acc.: 41.97%\n",
      "Time elapsed: 3.95 min\n",
      "Epoch: 107/200 | Batch 000/981 | Cost: 1.0704\n",
      "Epoch: 107/200 | Batch 200/981 | Cost: 0.9725\n",
      "Epoch: 107/200 | Batch 400/981 | Cost: 1.0042\n",
      "Epoch: 107/200 | Batch 600/981 | Cost: 0.9827\n",
      "Epoch: 107/200 | Batch 800/981 | Cost: 0.9978\n",
      "Epoch: 107/200 Train Acc.: 43.96% | Validation Acc.: 41.94%\n",
      "Time elapsed: 3.99 min\n",
      "Epoch: 108/200 | Batch 000/981 | Cost: 1.0702\n",
      "Epoch: 108/200 | Batch 200/981 | Cost: 0.9724\n",
      "Epoch: 108/200 | Batch 400/981 | Cost: 1.0033\n",
      "Epoch: 108/200 | Batch 600/981 | Cost: 0.9822\n",
      "Epoch: 108/200 | Batch 800/981 | Cost: 0.9973\n",
      "Epoch: 108/200 Train Acc.: 43.97% | Validation Acc.: 42.00%\n",
      "Time elapsed: 4.03 min\n",
      "Epoch: 109/200 | Batch 000/981 | Cost: 1.0700\n",
      "Epoch: 109/200 | Batch 200/981 | Cost: 0.9722\n",
      "Epoch: 109/200 | Batch 400/981 | Cost: 1.0023\n",
      "Epoch: 109/200 | Batch 600/981 | Cost: 0.9817\n",
      "Epoch: 109/200 | Batch 800/981 | Cost: 0.9967\n",
      "Epoch: 109/200 Train Acc.: 44.00% | Validation Acc.: 42.07%\n",
      "Time elapsed: 4.06 min\n",
      "Epoch: 110/200 | Batch 000/981 | Cost: 1.0697\n",
      "Epoch: 110/200 | Batch 200/981 | Cost: 0.9721\n",
      "Epoch: 110/200 | Batch 400/981 | Cost: 1.0014\n",
      "Epoch: 110/200 | Batch 600/981 | Cost: 0.9812\n",
      "Epoch: 110/200 | Batch 800/981 | Cost: 0.9962\n",
      "Epoch: 110/200 Train Acc.: 44.00% | Validation Acc.: 42.07%\n",
      "Time elapsed: 4.10 min\n",
      "Epoch: 111/200 | Batch 000/981 | Cost: 1.0695\n",
      "Epoch: 111/200 | Batch 200/981 | Cost: 0.9719\n",
      "Epoch: 111/200 | Batch 400/981 | Cost: 1.0004\n",
      "Epoch: 111/200 | Batch 600/981 | Cost: 0.9807\n",
      "Epoch: 111/200 | Batch 800/981 | Cost: 0.9957\n",
      "Epoch: 111/200 Train Acc.: 44.02% | Validation Acc.: 42.10%\n",
      "Time elapsed: 4.14 min\n",
      "Epoch: 112/200 | Batch 000/981 | Cost: 1.0692\n",
      "Epoch: 112/200 | Batch 200/981 | Cost: 0.9717\n",
      "Epoch: 112/200 | Batch 400/981 | Cost: 0.9994\n",
      "Epoch: 112/200 | Batch 600/981 | Cost: 0.9802\n",
      "Epoch: 112/200 | Batch 800/981 | Cost: 0.9952\n",
      "Epoch: 112/200 Train Acc.: 44.06% | Validation Acc.: 42.04%\n",
      "Time elapsed: 4.18 min\n",
      "Epoch: 113/200 | Batch 000/981 | Cost: 1.0690\n",
      "Epoch: 113/200 | Batch 200/981 | Cost: 0.9715\n",
      "Epoch: 113/200 | Batch 400/981 | Cost: 0.9985\n",
      "Epoch: 113/200 | Batch 600/981 | Cost: 0.9797\n",
      "Epoch: 113/200 | Batch 800/981 | Cost: 0.9947\n",
      "Epoch: 113/200 Train Acc.: 44.06% | Validation Acc.: 41.91%\n",
      "Time elapsed: 4.21 min\n",
      "Epoch: 114/200 | Batch 000/981 | Cost: 1.0687\n",
      "Epoch: 114/200 | Batch 200/981 | Cost: 0.9713\n",
      "Epoch: 114/200 | Batch 400/981 | Cost: 0.9975\n",
      "Epoch: 114/200 | Batch 600/981 | Cost: 0.9792\n",
      "Epoch: 114/200 | Batch 800/981 | Cost: 0.9941\n",
      "Epoch: 114/200 Train Acc.: 44.06% | Validation Acc.: 41.85%\n",
      "Time elapsed: 4.25 min\n",
      "Epoch: 115/200 | Batch 000/981 | Cost: 1.0685\n",
      "Epoch: 115/200 | Batch 200/981 | Cost: 0.9710\n",
      "Epoch: 115/200 | Batch 400/981 | Cost: 0.9965\n",
      "Epoch: 115/200 | Batch 600/981 | Cost: 0.9787\n",
      "Epoch: 115/200 | Batch 800/981 | Cost: 0.9936\n",
      "Epoch: 115/200 Train Acc.: 44.09% | Validation Acc.: 41.70%\n",
      "Time elapsed: 4.29 min\n",
      "Epoch: 116/200 | Batch 000/981 | Cost: 1.0682\n",
      "Epoch: 116/200 | Batch 200/981 | Cost: 0.9708\n",
      "Epoch: 116/200 | Batch 400/981 | Cost: 0.9955\n",
      "Epoch: 116/200 | Batch 600/981 | Cost: 0.9782\n",
      "Epoch: 116/200 | Batch 800/981 | Cost: 0.9930\n",
      "Epoch: 116/200 Train Acc.: 44.11% | Validation Acc.: 41.55%\n",
      "Time elapsed: 4.32 min\n",
      "Epoch: 117/200 | Batch 000/981 | Cost: 1.0679\n",
      "Epoch: 117/200 | Batch 200/981 | Cost: 0.9705\n",
      "Epoch: 117/200 | Batch 400/981 | Cost: 0.9946\n",
      "Epoch: 117/200 | Batch 600/981 | Cost: 0.9778\n",
      "Epoch: 117/200 | Batch 800/981 | Cost: 0.9925\n",
      "Epoch: 117/200 Train Acc.: 44.10% | Validation Acc.: 41.46%\n",
      "Time elapsed: 4.36 min\n",
      "Epoch: 118/200 | Batch 000/981 | Cost: 1.0676\n",
      "Epoch: 118/200 | Batch 200/981 | Cost: 0.9703\n",
      "Epoch: 118/200 | Batch 400/981 | Cost: 0.9936\n",
      "Epoch: 118/200 | Batch 600/981 | Cost: 0.9773\n",
      "Epoch: 118/200 | Batch 800/981 | Cost: 0.9919\n",
      "Epoch: 118/200 Train Acc.: 44.12% | Validation Acc.: 41.40%\n",
      "Time elapsed: 4.40 min\n",
      "Epoch: 119/200 | Batch 000/981 | Cost: 1.0673\n",
      "Epoch: 119/200 | Batch 200/981 | Cost: 0.9700\n",
      "Epoch: 119/200 | Batch 400/981 | Cost: 0.9926\n",
      "Epoch: 119/200 | Batch 600/981 | Cost: 0.9768\n",
      "Epoch: 119/200 | Batch 800/981 | Cost: 0.9913\n",
      "Epoch: 119/200 Train Acc.: 44.11% | Validation Acc.: 41.28%\n",
      "Time elapsed: 4.44 min\n",
      "Epoch: 120/200 | Batch 000/981 | Cost: 1.0670\n",
      "Epoch: 120/200 | Batch 200/981 | Cost: 0.9697\n",
      "Epoch: 120/200 | Batch 400/981 | Cost: 0.9917\n",
      "Epoch: 120/200 | Batch 600/981 | Cost: 0.9764\n",
      "Epoch: 120/200 | Batch 800/981 | Cost: 0.9908\n",
      "Epoch: 120/200 Train Acc.: 44.13% | Validation Acc.: 41.19%\n",
      "Time elapsed: 4.47 min\n",
      "Epoch: 121/200 | Batch 000/981 | Cost: 1.0667\n",
      "Epoch: 121/200 | Batch 200/981 | Cost: 0.9694\n",
      "Epoch: 121/200 | Batch 400/981 | Cost: 0.9907\n",
      "Epoch: 121/200 | Batch 600/981 | Cost: 0.9759\n",
      "Epoch: 121/200 | Batch 800/981 | Cost: 0.9902\n",
      "Epoch: 121/200 Train Acc.: 44.14% | Validation Acc.: 41.01%\n",
      "Time elapsed: 4.51 min\n",
      "Epoch: 122/200 | Batch 000/981 | Cost: 1.0663\n",
      "Epoch: 122/200 | Batch 200/981 | Cost: 0.9691\n",
      "Epoch: 122/200 | Batch 400/981 | Cost: 0.9898\n",
      "Epoch: 122/200 | Batch 600/981 | Cost: 0.9755\n",
      "Epoch: 122/200 | Batch 800/981 | Cost: 0.9896\n",
      "Epoch: 122/200 Train Acc.: 44.13% | Validation Acc.: 40.85%\n",
      "Time elapsed: 4.55 min\n",
      "Epoch: 123/200 | Batch 000/981 | Cost: 1.0660\n",
      "Epoch: 123/200 | Batch 200/981 | Cost: 0.9688\n",
      "Epoch: 123/200 | Batch 400/981 | Cost: 0.9888\n",
      "Epoch: 123/200 | Batch 600/981 | Cost: 0.9750\n",
      "Epoch: 123/200 | Batch 800/981 | Cost: 0.9889\n",
      "Epoch: 123/200 Train Acc.: 44.16% | Validation Acc.: 40.91%\n",
      "Time elapsed: 4.59 min\n",
      "Epoch: 124/200 | Batch 000/981 | Cost: 1.0657\n",
      "Epoch: 124/200 | Batch 200/981 | Cost: 0.9685\n",
      "Epoch: 124/200 | Batch 400/981 | Cost: 0.9878\n",
      "Epoch: 124/200 | Batch 600/981 | Cost: 0.9746\n",
      "Epoch: 124/200 | Batch 800/981 | Cost: 0.9883\n",
      "Epoch: 124/200 Train Acc.: 44.18% | Validation Acc.: 40.88%\n",
      "Time elapsed: 4.62 min\n",
      "Epoch: 125/200 | Batch 000/981 | Cost: 1.0653\n",
      "Epoch: 125/200 | Batch 200/981 | Cost: 0.9682\n",
      "Epoch: 125/200 | Batch 400/981 | Cost: 0.9869\n",
      "Epoch: 125/200 | Batch 600/981 | Cost: 0.9741\n",
      "Epoch: 125/200 | Batch 800/981 | Cost: 0.9877\n",
      "Epoch: 125/200 Train Acc.: 44.19% | Validation Acc.: 40.85%\n",
      "Time elapsed: 4.66 min\n",
      "Epoch: 126/200 | Batch 000/981 | Cost: 1.0650\n",
      "Epoch: 126/200 | Batch 200/981 | Cost: 0.9679\n",
      "Epoch: 126/200 | Batch 400/981 | Cost: 0.9860\n",
      "Epoch: 126/200 | Batch 600/981 | Cost: 0.9737\n",
      "Epoch: 126/200 | Batch 800/981 | Cost: 0.9871\n",
      "Epoch: 126/200 Train Acc.: 44.23% | Validation Acc.: 40.94%\n",
      "Time elapsed: 4.70 min\n",
      "Epoch: 127/200 | Batch 000/981 | Cost: 1.0646\n",
      "Epoch: 127/200 | Batch 200/981 | Cost: 0.9675\n",
      "Epoch: 127/200 | Batch 400/981 | Cost: 0.9850\n",
      "Epoch: 127/200 | Batch 600/981 | Cost: 0.9733\n",
      "Epoch: 127/200 | Batch 800/981 | Cost: 0.9864\n",
      "Epoch: 127/200 Train Acc.: 44.25% | Validation Acc.: 41.01%\n",
      "Time elapsed: 4.73 min\n",
      "Epoch: 128/200 | Batch 000/981 | Cost: 1.0643\n",
      "Epoch: 128/200 | Batch 200/981 | Cost: 0.9672\n",
      "Epoch: 128/200 | Batch 400/981 | Cost: 0.9841\n",
      "Epoch: 128/200 | Batch 600/981 | Cost: 0.9729\n",
      "Epoch: 128/200 | Batch 800/981 | Cost: 0.9857\n",
      "Epoch: 128/200 Train Acc.: 44.25% | Validation Acc.: 41.04%\n",
      "Time elapsed: 4.77 min\n",
      "Epoch: 129/200 | Batch 000/981 | Cost: 1.0639\n",
      "Epoch: 129/200 | Batch 200/981 | Cost: 0.9669\n",
      "Epoch: 129/200 | Batch 400/981 | Cost: 0.9832\n",
      "Epoch: 129/200 | Batch 600/981 | Cost: 0.9724\n",
      "Epoch: 129/200 | Batch 800/981 | Cost: 0.9851\n",
      "Epoch: 129/200 Train Acc.: 44.25% | Validation Acc.: 41.01%\n",
      "Time elapsed: 4.81 min\n",
      "Epoch: 130/200 | Batch 000/981 | Cost: 1.0635\n",
      "Epoch: 130/200 | Batch 200/981 | Cost: 0.9666\n",
      "Epoch: 130/200 | Batch 400/981 | Cost: 0.9822\n",
      "Epoch: 130/200 | Batch 600/981 | Cost: 0.9720\n",
      "Epoch: 130/200 | Batch 800/981 | Cost: 0.9844\n",
      "Epoch: 130/200 Train Acc.: 44.26% | Validation Acc.: 41.10%\n",
      "Time elapsed: 4.85 min\n",
      "Epoch: 131/200 | Batch 000/981 | Cost: 1.0631\n",
      "Epoch: 131/200 | Batch 200/981 | Cost: 0.9662\n",
      "Epoch: 131/200 | Batch 400/981 | Cost: 0.9813\n",
      "Epoch: 131/200 | Batch 600/981 | Cost: 0.9716\n",
      "Epoch: 131/200 | Batch 800/981 | Cost: 0.9837\n",
      "Epoch: 131/200 Train Acc.: 44.25% | Validation Acc.: 41.13%\n",
      "Time elapsed: 4.88 min\n",
      "Epoch: 132/200 | Batch 000/981 | Cost: 1.0627\n",
      "Epoch: 132/200 | Batch 200/981 | Cost: 0.9659\n",
      "Epoch: 132/200 | Batch 400/981 | Cost: 0.9804\n",
      "Epoch: 132/200 | Batch 600/981 | Cost: 0.9712\n",
      "Epoch: 132/200 | Batch 800/981 | Cost: 0.9830\n",
      "Epoch: 132/200 Train Acc.: 44.31% | Validation Acc.: 41.04%\n",
      "Time elapsed: 4.92 min\n",
      "Epoch: 133/200 | Batch 000/981 | Cost: 1.0624\n",
      "Epoch: 133/200 | Batch 200/981 | Cost: 0.9656\n",
      "Epoch: 133/200 | Batch 400/981 | Cost: 0.9795\n",
      "Epoch: 133/200 | Batch 600/981 | Cost: 0.9708\n",
      "Epoch: 133/200 | Batch 800/981 | Cost: 0.9823\n",
      "Epoch: 133/200 Train Acc.: 44.33% | Validation Acc.: 41.04%\n",
      "Time elapsed: 4.96 min\n",
      "Epoch: 134/200 | Batch 000/981 | Cost: 1.0620\n",
      "Epoch: 134/200 | Batch 200/981 | Cost: 0.9653\n",
      "Epoch: 134/200 | Batch 400/981 | Cost: 0.9786\n",
      "Epoch: 134/200 | Batch 600/981 | Cost: 0.9704\n",
      "Epoch: 134/200 | Batch 800/981 | Cost: 0.9816\n",
      "Epoch: 134/200 Train Acc.: 44.35% | Validation Acc.: 41.01%\n",
      "Time elapsed: 5.00 min\n",
      "Epoch: 135/200 | Batch 000/981 | Cost: 1.0616\n",
      "Epoch: 135/200 | Batch 200/981 | Cost: 0.9650\n",
      "Epoch: 135/200 | Batch 400/981 | Cost: 0.9777\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-324016783fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m### FORWARD AND BACK PROP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         print(cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-f73207fa3d63>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#         out = torch.sigmoid(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.view(-1, num_features).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features.float())\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, valid_acc_lst = [], []\n",
    "train_loss_lst, valid_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.view(-1, num_features).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features.float())\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "#         print(cost)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 200:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "        valid_acc, valid_loss = compute_accuracy_and_loss(model, valid_loader, device=DEVICE)\n",
    "        train_acc_lst.append(train_acc)\n",
    "        valid_acc_lst.append(valid_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (No Need To Change Any Code in This Section!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_loss_lst, label='Training loss')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), valid_loss_lst, label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_acc_lst, label='Training accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), valid_acc_lst, label='Validation accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.24%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, DEVICE)\n",
    "    print(f'Test accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions (YOUR ANSWERS REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) What is your training, validation, and test accuracy (paste your numbers from above)? Also, do you notice any overfitting? If yes, why do you think your model is overfitting, and what would be a simple technique to reduce overfitting?**\n",
    "\n",
    "- Training:  94.52%\n",
    "- Validation: 89.68%\n",
    "- Test 89.24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes: \n",
    "- Added 3 hidden layers with 1000 units each and Relu activations\n",
    "- Changed output activation function to Softmax\n",
    "- Increased the learning rate to 0.1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the model is overfitting because the training accuracy keeps improving while the validation accuracy stays the same or decreases after a certain point. This implies that the model is learning too much about the training data and hence, overfitting. A simple way to reduce overfitting would be to use L1/L2 regularization, add dropout layers or reduce the complexity/capacity of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Assuming you increased the accuracy by 3%, how many more correct predictions did the improved model make in the test set?**\n",
    "\n",
    "The test dataset has 10,000 images. So, a 3% increase in accuracy means that the model made 300 more correct predictions.\n",
    "\n",
    "10000 * 0.03 = 300 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
